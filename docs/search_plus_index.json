{"./":{"url":"./","title":"Computer Science Recapitulaion","keywords":"","body":"CS Recap ここではComputer Scienceに関連する分野で自分が勉強した内容を書いていきます 間違った内容などがあったら是非青い鳥にDM or リプライをするかプルリクエストをして下さい 文中ではOSをUbuntu(18.04以降)かMac OSを(Mojave以降)を想定しています 内容に関する注意 本文に従って何かしらの不利益を被った際の責任は取りませんのであしからず Core CSの基礎となるような内容です Math Calculus Linear algebra Statistics Set & Phase Physics Electromagnetics CS Discrete Math Algorithm Computer Architecture C Language Selective Coreの内容を土台とする発展的な内容です Information theory Operating system Other topics 関連した内容です Editor Latex Git "},"cal/cal.html":{"url":"cal/cal.html","title":"Calculus","keywords":"","body":"Calculus "},"linear-alge/linear-alge.html":{"url":"linear-alge/linear-alge.html","title":"Linear algebra","keywords":"","body":"Linear algebra "},"stat/stat.html":{"url":"stat/stat.html","title":"Statistics","keywords":"","body":"Statistics "},"set-phase/set-phase.html":{"url":"set-phase/set-phase.html","title":"Set & Phase","keywords":"","body":"Set & Phase "},"elec/elec.html":{"url":"elec/elec.html","title":"Electromagnetics","keywords":"","body":"Electromagnetics "},"elec/math.html":{"url":"elec/math.html","title":"Basic Math","keywords":"","body":"Basic Math "},"elec/cou-gau.html":{"url":"elec/cou-gau.html","title":"Coulomb & Gaussian","keywords":"","body":"Coulomb & Gaussian "},"elec/potential.html":{"url":"elec/potential.html","title":"Potential","keywords":"","body":"Potential "},"dis-math/dis-math.html":{"url":"dis-math/dis-math.html","title":"Discrete Math","keywords":"","body":"Discrete Math "},"dis-math/set.html":{"url":"dis-math/set.html","title":"Set","keywords":"","body":"Set "},"dis-math/proof.html":{"url":"dis-math/proof.html","title":"Proof","keywords":"","body":"Proof "},"algo/algo.html":{"url":"algo/algo.html","title":"Algorithm","keywords":"","body":"Algorithm OS,暗号技術,人工知能,ネットワーク,コンパイラー...などなどあらゆる情報科学の分野で必要となる知識 Order "},"algo/order.html":{"url":"algo/order.html","title":"Order","keywords":"","body":"Order アルゴリズムを考える際,一つの指標となるのが計算量です 計算量とは空間計算量･時間計算量がありますがどちらも基本となる考え方は同じです ここでは時間計算量について考えます Asymptotic Analysis 計算量とはそのアルゴリズムがどのような関数に漸近するのかを考えたものです そのため,以下のようなメリット･デメリットがあります メリット 環境に依存しないアルゴリズムそのものの良し悪しについて考えられる よりアルゴリズムを取り扱いやすくする デメリット 入力が大きい時しか考慮していない この計算量を求める方法は Tree Method Master Theorem(Generalized Method) Substitution Method 以上の3種類が有ります Tree Methodを一般化したものなので以下ではMaster TheoremとSustitution Method を扱います その前に計算量の記法について学びましょう 計算量記法 ここではBig-O記法･Big-Omega記法･Big-Theta記法について考えます Big-O T(n)T(n)T(n)(計算にかかる時間で,値は正で単調増加だとします)とg(n)g(n)g(n)が正の整数の関数だとします ∃c,n0>0 s.t. ∀n≥n00≤T(n)≤cg(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq T(n) \\leq cg(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤T(n)≤cg(n)​ であるとき,T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))とします ` ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも小さいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の上限であるということです T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))はT(n)=O(g(n))T(n) = O(g(n))T(n)=O(g(n))とも書きます(こう書く場合の方が多いです) Big-Omega Big-O記法は上限を表現するためでしたが,Big-Omega記法は下限を表現するための記法です 上と同じ関数T(n)T(n)T(n)とg(n)g(n)g(n)を用いて ∃c,n0>0 s.t. ∀n≥n00≤cg(n)≤T(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq cg(n) \\leq T(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤cg(n)≤T(n)​ のときT(n)∈Ω(g(n))T(n) \\in \\Omega(g(n))T(n)∈Ω(g(n))もしくはT(n)=Ω(g(n))T(n) = \\Omega(g(n))T(n)=Ω(g(n))とします ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも大きいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の下限であるということです Big-Theta Big-Theta記法は上の記法のどちらもが当てはまるときです つまり,以下の式を満たします ∃c0,c1,n0>0 s.t. ∀n≤n00≤c0⋅g(n)≤f(n)≤c1⋅g(n) \\begin{aligned} \\exists{c_0, c_1, n_0} &> 0 \\text{ s.t. } \\forall{n} \\leq n_0 \\\\ 0 &\\leq c_0 \\cdot g(n) \\leq f(n) \\leq c_1\\cdot g(n) \\end{aligned} ∃c0​,c1​,n0​0​>0 s.t. ∀n≤n0​≤c0​⋅g(n)≤f(n)≤c1​⋅g(n)​ Big-Theta記法は無限に大きいnnnでg(n)g(n)g(n)の定数倍にT(n)T(n)T(n)が挟まれる状態にあるということです Master Theorem 最初に定理を紹介し,あとから説明をします a≥1a\\geq 1a≥1, b≥1b \\geq 1b≥1, dddをnnnに独立な定数とします このときT(n)=a⋅T(nb)+O(nd)T(n)=a \\cdot T(\\frac{n}{b}) + O(n^d)T(n)=a⋅T(bn​)+O(nd)とすると以下の式を満たします T(n)={O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb(a))(a>bd) T(n) = \\begin{cases} O(n^{d}log(n)) (a = b^d) \\\\ O(n^d) (a b^d) \\end{cases} T(n)=⎩⎪⎨⎪⎧​O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb​(a))(a>bd)​ この定理を分類定理(master theorem)と言います aaa : 分割された下位問題の数 bbb : 入力の大きさが縮む倍率(2→12 \\rightarrow 12→1のときはb=2b=2b=2) ddd : 全ての問題を分割し統合するのに必要な計算量 この定理は問題を分割し,それらを更に分割し解くという考えを使っています(これを再帰と言います) 入力がnnnの問題をT(n)T(n)T(n)で解くアルゴリズムを考えます 入力nnnをaaa個に分割する 分割された入力をT(nb)T(\\frac{n}{b})T(bn​)で解く 分割された各アルゴリズムに対してかかる時間が(O(nlog⁡b(a))(O(n^{\\log_{b}(a)})(O(nlogb​(a))である このようにするとT(n)T(n)T(n)は上のような式になります.実際にそれぞれのケースごとに正しいか確認してみましょう a=bda=b^da=bdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t=c⋅nd⋅∑t=0log⁡b(n)1=c⋅nd⋅(log⁡b(n)+1)=c⋅nd⋅(log⁡(n)log⁡(b)+1)=O(ndlog⁡(n)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t \\\\ &= c \\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}1 \\\\ &= c \\cdot n^d \\cdot (\\log_b(n) + 1) \\\\ &= c \\cdot n^d \\cdot (\\frac{\\log(n)}{\\log(b)} + 1) \\\\ &= O(n^d \\log(n)) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t=c⋅nd⋅t=0∑logb​(n)​1=c⋅nd⋅(logb​(n)+1)=c⋅nd⋅(log(b)log(n)​+1)=O(ndlog(n))​ abda abdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満 T(n) = c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} T(n)=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​ ここで,等比級数の和は一般項xxxが1より大きい時は次数が最大の項が支配的になり,xxxが0より大きく1より小さい時は次数が最小の項が支配的になる ここでは∑t=0log⁡b(n)(abd)t\\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t∑t=0logb​(n)​(bda​)tの一般項は後者なので定数として扱える T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満=c⋅nd⋅定数=O(nd) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} \\\\ &= c \\cdot n^d \\cdot \\text{定数} \\\\ &= O(n^d) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​=c⋅nd⋅定数=O(nd)​ a>bda > b^da>bdの場合 上の例で扱ったように一般項に注目する T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1より大きい=O(nd(abdlogb(n)))=O(nlog⁡b(a)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{より大きい}} \\\\ &=O(n^d(\\frac{a}{b^d}^{log_b(n)})) \\\\ &=O(n^{\\log_b(a)}) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1より大きい​=O(nd(bda​logb​(n)))=O(nlogb​(a))​ Substitution Method これは以下の手順から成り立ちます 答えを推論する その推論が正しいと証明する 答えを得る 例 T(n)=2⋅T(n2)+nT(n) = 2 \\cdot T(\\frac{n}{2}) + nT(n)=2⋅T(2n​)+nという例をここでは扱います(ただしT(1)=1T(1)=1T(1)=1). 推論 この時,実際に手を動かしてみると T(n)=2⋅T(n2)+n=2⋅(2⋅T(n4)+n2)+n=4⋅T(n4)+2n=4⋅T(2⋅T(n8)+n4)+2n=8⋅T(n8)+3n=⋯ \\begin{aligned} T(n) &= 2 \\cdot T(\\frac{n}{2}) + n \\\\ &=2 \\cdot (2 \\cdot T(\\frac{n}{4}) + \\frac{n}{2}) + n \\\\ &= 4 \\cdot T(\\frac{n}{4}) + 2n \\\\ &= 4 \\cdot T(2 \\cdot T(\\frac{n}{8}) + \\frac{n}{4}) + 2n \\\\ &= 8 \\cdot T(\\frac{n}{8}) + 3n &= \\cdots \\end{aligned} T(n)​=2⋅T(2n​)+n=2⋅(2⋅T(4n​)+2n​)+n=4⋅T(4n​)+2n=4⋅T(2⋅T(8n​)+4n​)+2n=8⋅T(8n​)+3n​=⋯​ このようになり, T(n)=2t⋅T(n2t)+t⋅nT(n) = 2^t \\cdot T(\\frac{n}{2^t})+ t\\cdot nT(n)=2t⋅T(2tn​)+t⋅nになるのではないかと推測できます t=log(n)t=log(n)t=log(n)を代入し, T(n)=n⋅T(1)+log⁡(n)⋅(n)⋅n=n(log⁡(n)+1) T(n)= n \\cdot T(1) + \\log(n) \\cdot(n) \\cdot n = n(\\log(n) + 1) T(n)=n⋅T(1)+log(n)⋅(n)⋅n=n(log(n)+1) と推論できます 証明 数学的帰納法で証明します Inductive Hypothesis T(j)=j(log⁡(j)+1)T(j) = j(\\log(j)+1)T(j)=j(log(j)+1)が1≤j≤n1 \\leq j \\leq n1≤j≤nで成り立つと仮定します Base Case(n=1n=1n=1) T(1)=1=1⋅(log⁡(1)+1)T(1) = 1 = 1 \\cdot (\\log(1) + 1)T(1)=1=1⋅(log(1)+1)となり成り立ちます Inductive Step inductive hypothesisがn=k−1n=k-1n=k−1で成り立つと仮定します このとき定義からT(k)=2⋅T(k2)+kT(k)= 2 \\cdot T(\\frac{k}{2}) + kT(k)=2⋅T(2k​)+kであり,仮定よりT(k)=2⋅(k2(log⁡(k2)+1))+kT(k)= 2 \\cdot (\\frac{k}{2}(\\log(\\frac{k}{2})+1))+kT(k)=2⋅(2k​(log(2k​)+1))+kです.簡単にすると, T(k)=k(log⁡(k)+2) T(k)=k (\\log(k) + 2) T(k)=k(log(k)+2) となり,n=kn=kn=kでも成り立つことが示されました 結論 n≥1n \\geq 1n≥1 で T(n)=n(log⁡(n)+1)T(n) = n(\\log(n) + 1)T(n)=n(log(n)+1)とわかります このように事前の推論を数学的帰納法で証明することをSubstituion Methodと言います まとめ 計算量という概念を導入することでアルゴリズムの良し悪しが分かる 計算量を導く方法がある "},"comp-arch/comp-arch.html":{"url":"comp-arch/comp-arch.html","title":"Computer Architecture","keywords":"","body":"Computer Architecture "},"clang/clang.html":{"url":"clang/clang.html","title":"C Language","keywords":"","body":"C Language "},"clang/c-intro.html":{"url":"clang/c-intro.html","title":"Introduction to C","keywords":"","body":"Introduction to C "},"info-theo/info-theo.html":{"url":"info-theo/info-theo.html","title":"Information theory","keywords":"","body":"Information Theory 情報理論とは情報を数量的に捉える理論のことです Entropy Information Resource "},"info-theo/entropy.html":{"url":"info-theo/entropy.html","title":"Entropy","keywords":"","body":"Entropy "},"info-theo/info-res.html":{"url":"info-theo/info-res.html","title":"Information Resource","keywords":"","body":"Information Resource "},"info-geo/info-geo.html":{"url":"info-geo/info-geo.html","title":"Information geometry","keywords":"","body":"Information geometry "},"os/os.html":{"url":"os/os.html","title":"Operating system","keywords":"","body":"Operating system "},"os/intro.html":{"url":"os/intro.html","title":"Introduction to OS","keywords":"","body":"Introduction to OS "},"os/thread-proc.html":{"url":"os/thread-proc.html","title":"Thread & Process","keywords":"","body":"Thread & Process "},"os/c-assem.html":{"url":"os/c-assem.html","title":"C & Assembly","keywords":"","body":"C & Assembly "},"other/editor.html":{"url":"other/editor.html","title":"Editor","keywords":"","body":"Editor "},"other/latex.html":{"url":"other/latex.html","title":"Latex","keywords":"","body":"Latex "},"other/git.html":{"url":"other/git.html","title":"Git","keywords":"","body":"Git "}}