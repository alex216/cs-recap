{"./":{"url":"./","title":"Computer Science Recapitulaion","keywords":"","body":"CS Recap ここではComputer Scienceに関連する分野で自分が勉強した内容を書いていきます 間違った内容などがあったら是非青い鳥にDM or リプライをするかプルリクエストをして下さい 文中ではOSをUbuntu(18.04以降)かMac OSを(Mojave以降)を想定しています 内容に関する注意 本文に従って何かしらの不利益を被った際の責任は取りませんのであしからず Core CSの基礎となるような内容です Math Calculus Linear algebra Statistics Set & Topology Physics Electromagnetics CS Discrete Math Algorithm Computer Architecture C Language Selective Coreの内容を土台とする発展的な内容です Information theory Operating system Other topics 関連した内容です Editor Latex Git "},"cal/cal00.html":{"url":"cal/cal00.html","title":"Calculus","keywords":"","body":"Calculus "},"linear-alge/linear-alge00.html":{"url":"linear-alge/linear-alge00.html","title":"Linear algebra","keywords":"","body":"Linear algebra "},"stat/stat00.html":{"url":"stat/stat00.html","title":"Statistics","keywords":"","body":"Statistics "},"set-topology/set-phase00.html":{"url":"set-topology/set-phase00.html","title":"Set & Topology","keywords":"","body":"Set & Topology "},"elec/elec00.html":{"url":"elec/elec00.html","title":"Electromagnetics","keywords":"","body":"Electromagnetics 多くのコンピュータの動力源である電気と磁気についての理論 Basic Math Coulomb & Gaussian Potential "},"elec/elec01.html":{"url":"elec/elec01.html","title":"01 Basic Math","keywords":"","body":"01 Basic Math 電磁気で用いる数学についてやります ベクトル解析 電磁気では多くの数学が使われます ここではそのうち最も重要であるベクトル解析について簡単に触れます スカラー積とベクトル積 スカラー積は内積,ベクトル積は外積とも呼びます ベクトルA\\bm{A}AとベクトルB\\bm{B}Bのスカラー積とは,A\\bm{A}Aの大きさにB\\bm{B}BのA\\bm{A}Aのに落とした正射影の成分の大きさをかけたものです 式では次のように書きます A⋅B=∣A∣∣B∣cos⁡θ \\bm{A} \\cdot \\bm{B} = |A||B|\\cos\\theta A⋅B=∣A∣∣B∣cosθ また A⋅B=AxBx+AyBy \\bm{A} \\cdot \\bm{B} = A_x B_x + A_y B_y A⋅B=Ax​Bx​+Ay​By​ となるのも,AxByA_x B_yAx​By​などが直行してxxx軸に対して(もしくはy軸に対して)大きさがないからです ベクトル積は回転が関係します ベクトルrrrとベクトルFFFのベクトル積はrrrからFFFにひねった方向に回転し,それに対する右ねじの方向に向いた力です 例えばxxx, yyy, zzz軸方向に大きさ1の単位ベクトルがあるとして xxx同士の掛け算は回転しないので大きさ000のベクトル xxxとyyyの掛け算は回転するので大きさ111のzzz方向へのベクトル yyyとxxxの掛け算は回転するので大きさ111の−z-z−z方向へのベクトル 微分 偏微分 偏微分は変数を定数として見るというものです 偏微分は∂\\partial∂を使って演算をします おそらく問題ないと思います 全微分 全微分は以下のような式です Δf=∂f∂xΔx+∂f∂yΔy+∂f∂zΔz \\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x + \\frac{\\partial f}{\\partial y}\\Delta y + \\frac{\\partial f}{\\partial z}\\Delta z Δf=∂x∂f​Δx+∂y∂f​Δy+∂z∂f​Δz この数式がどのようなイメージを持つかを説明するため,x−yx-yx−yの2次元に次元を落として考えます 場の量fffはx−yx-yx−y平面上で定義された量でかつスカラーとしておけばx−yx-yx−y平面上を覆うような曲面だということがわかると思います この微小な領域を考えます その微小な領域のxxx, yyy方向での変化をそれぞれΔx\\Delta xΔx, Δy\\Delta yΔyとすると,zzz軸方向の変化は∂f∂yΔy+∂f∂xΔx\\frac{\\partial f}{\\partial y}\\Delta y + \\frac{\\partial f}{\\partial x}\\Delta x∂y∂f​Δy+∂x∂f​Δx つまり,全微分とはそのような微小な領域の体積を求めているのです ∇\\nabla∇関連の公式の意味 gradψ\\psiψ(∇ψ\\nabla \\psi∇ψ) スカラー場ψ\\psiψから傾斜を求めるときに使うのがgradψgrad \\psigradψ(∇ψ\\nabla \\psi∇ψ)です これも全微分の例と同様に考えることが可能です つまり,スカラー場ψ\\psiψの最大傾斜の方向を向き,傾斜が大きければ大きいほどその値も大きなベクトルです divAdiv AdivA(∇A\\nabla A∇A) 具体的に divD=ρ div \\bm{D} = \\rho divD=ρ を考えてみます この式の両辺に微小体積ΔV\\Delta VΔVをかけるとh divDΔV=ρΔV div \\bm{D} \\Delta V = \\rho \\Delta V divDΔV=ρΔV 右辺はρ\\rhoρを電荷密度としてその体積の中にある電気量の合計です divDΔV=(∂Dx∂x+∂Dy∂y+∂Dz∂z)ΔxΔyΔz div \\bm{D} \\Delta V = \\left( \\frac{\\partial D_x}{\\partial x} + \\frac{\\partial D_y}{\\partial y} + \\frac{\\partial D_z}{\\partial z} \\right) \\Delta x \\Delta y \\Delta z divDΔV=(∂x∂Dx​​+∂y∂Dy​​+∂z∂Dz​​)ΔxΔyΔz ここで∂Dx/∂x\\partial D_x / \\partial x∂Dx​/∂xだけを考えます ∂Dx∂xΔxΔyΔz=∂Dx∂xΔx⋅ΔyΔz \\frac{\\partial D_x}{\\partial x}\\Delta x \\Delta y \\Delta z = \\frac{\\partial D_x}{\\partial x}\\Delta x \\cdot \\Delta y \\Delta z ∂x∂Dx​​ΔxΔyΔz=∂x∂Dx​​Δx⋅ΔyΔz となります.このとき∂Dx∂x\\frac{\\partial D_x}{\\partial x}∂x∂Dx​​はΔx\\Delta xΔxだけ変化したDxD_xDx​の増加分なので次のように書けます ∂Dx∂xΔx⋅ΔyΔz=Δx(x+Δx)−Δx(x)ΔyΔz \\frac{\\partial D_x}{\\partial x}\\Delta x \\cdot \\Delta y \\Delta z = { \\Delta_x (x + \\Delta x) - \\Delta_x(x)} \\Delta y \\Delta z ∂x∂Dx​​Δx⋅ΔyΔz=Δx​(x+Δx)−Δx​(x)ΔyΔz つまり,微小な面を通過する電束の差分です この値を積分すると体積全体から出てくる電束を求めることができます.よって ∫VdivDdV=∫SD⋅dS \\int_V div \\bm{D} dV = \\int_S \\bm{D} \\cdot dS ∫V​divDdV=∫S​D⋅dS という書くことができます.Δ\\DeltaΔを電束密度に限らず,任意のベクトルにするとA\\bm{A}Aと書け, ∫VdivAdV=∫SA⋅ndS \\int_V div \\bm{A} dV = \\int_S \\bm{A} \\cdot \\bm{n} dS ∫V​divAdV=∫S​A⋅ndS と書くことができます.これは体積積分とその表面の面積積分の関係を示す公式でガウスの定理と言います(電磁気の場合はガウスの法則) rotArot ArotA(∇×A\\nabla \\times A∇×A) これは回転のイメージです ここでもΔx\\Delta xΔxに関してだけ見ると計算結果は (∂Ay∂x−∂Ax∂y)ΔxΔy \\left( \\frac{\\partial A_y}{\\partial x} - \\frac{\\partial A_x}{\\partial y} \\right) \\Delta x \\Delta y (∂x∂Ay​​−∂y∂Ax​​)ΔxΔy となります.これは 回転の効果を足したもの=(Δ×A大きさ×(経路で囲まれる面積)) \\text{回転の効果を足したもの} = (\\Delta \\times \\bm{A}\\text{大きさ} \\times (\\text{経路で囲まれる面積})) 回転の効果を足したもの=(Δ×A大きさ×(経路で囲まれる面積)) という意味を持ちます.つまりこの値に対して線積分をすれば ∮CA⋅ds=∫s(Δ×A)n⋅dS \\oint_C \\bm{A} \\cdot d\\bm{s} = \\int_s (\\Delta \\times \\bm{A})_n \\cdot dS ∮C​A⋅ds=∫s​(Δ×A)n​⋅dS これがストークスの定理です ガウスの定理は体積積分と面積分の関係ですが,ストークスの定理は線積分と面積積分の関係です ラプラシアン(∇⋅(∇ψ)\\nabla \\cdot (\\nabla \\psi )∇⋅(∇ψ)) gradのdivdivdivです ∇×(∇ψ)=0\\nabla \\times (\\nabla \\psi) = 0∇×(∇ψ)=0 ∇\\nabla∇を掛けた(grad)場合,xxx成分にはyyy成分とzzz成分のみしかないので,それに∇\\nabla∇をベクトル積したもの(rot)は当然000のベクトルとなります ∇⋅(∇×A)=0\\nabla \\cdot (\\nabla \\times A) = 0∇⋅(∇×A)=0 これも上と変わりません 物理的なイメージを考えれば当然の式です "},"elec/elec02.html":{"url":"elec/elec02.html","title":"02 Coulomb & Gaussian","keywords":"","body":"02 Coulomb & Gaussian クーロンの法則 2つの点電荷の間にどのような力が働くかを示す法則です 電気量q1q_1q1​の点電荷AAAと電気量q2q_2q2​の点電荷BBBがあるとして,その距離がrrrのとき,その間に働くクーロン力(静電気力)の大きさFFFは F=kq1q2r F = k \\frac{q_1 q_2}{r} F=krq1​q2​​ ただし,k=14πε0k = \\frac{1}{4 \\pi \\varepsilon_0}k=4πε0​1​は比例定数です またAAAがBBBから受け取るクーロン力は FAB=14πε0q1q2r3r F_{\\bm{A}\\bm{B}} = \\frac{1}{4\\pi \\varepsilon_0}\\frac{q_1 q_2}{r^3}\\bm{r} FAB​=4πε0​1​r3q1​q2​​r と表せます 電場 電場とは点電荷から湧き出るエネルギーのようなものです クーロンの法則から電場は E=q4πε0r2n \\bm{E} = \\frac{q}{4 \\pi \\varepsilon_0 r^2}\\bm{n} E=4πε0​r2q​n と定義できます それを電気力線という架空の存在で表現します.わかりやすく1クーロンで1本という風に決めます このとき,あるq(>0)q(>0)q(>0)の電気量を持った点電荷からqqq本の電気力線が湧き出ています.点電荷を中心とした球面の表面積は4πr24\\pi r^24πr2なので球面上での電気力線の密度DDDは D=q4πr2 D = \\frac{q}{4 \\pi r^2} D=4πr2q​ ベクトルで表現すると(n\\bm{n}nは球の中心から外側に向かう単位ベクトル) D=q4πr2n D = \\frac{q}{4 \\pi r^2}\\bm{n} D=4πr2q​n 電気力線の密度は電束密度と呼び,電気力線のことは電束と呼びます ここで電束密度の式とクーロンの法則で定義した電場の式を比べる.すると両者の違いは1/ε01 / \\varepsilon_01/ε0​しかないことがわかります この違いは単位を揃えるための便宜的なものです ここでは電気量qqqの点電荷から生じる電気力線の本数を電束密度と電場の単位を揃えるためにq/ε0q / \\varepsilon_0q/ε0​とします ガウスの法則 点電荷を囲む球面から通って出ていく電気力線の本数は点電荷の持つ電気量(÷ε0\\div \\varepsilon_0÷ε0​)に等しいというのは直感的に理解できます この関係を式で表すのがガウスの法則です 電気力線が面を直角に通過する時はその本数は｢電場(電気力線の密度) ×\\times× 面積｣ですが,斜めに通過する可能性もあります 通過する面積は実質的にはdScos⁡θdS\\cos \\thetadScosθとなっているので,面に対する単位法線ベクトルn\\bm{n}nを用いて ∫SE⋅ndS=qε0 \\int_S \\bm{E} \\cdot \\bm{n} dS = \\frac{q}{\\varepsilon_0} ∫S​E⋅ndS=ε0​q​ と表わせ,これがガウスの法則です 左辺はガウスの定理によって ∫SE⋅ndS=∫VdivEdV \\int_S \\bm{E} \\cdot \\bm{n} dS = \\int_V div \\bm{E} dV ∫S​E⋅ndS=∫V​divEdV となります 左辺は｢電気力線の密度と面積｣から求めた電気量です.右辺は｢電気力線の湧き出しと体積｣から求めた電気量です そこで微小な領域dVdVdVで電場の式は divEdV=qε0 div \\bm{E}dV = \\frac{q}{\\varepsilon_0} divEdV=ε0​q​ 確認ですがqε0\\frac{q}{\\varepsilon_0}ε0​q​は電気力線の数です ここで,微小領域に存在する電荷の密度[C/m3][C/m^3][C/m3]を ρ=qdV \\rho = \\frac{q}{dV} ρ=dVq​ とすれば divE=ρε0 div\\bm{E} = \\frac{\\rho}{\\varepsilon_0} divE=ε0​ρ​ となります.これはマクスウェル方程式の1つです これを電解密度D\\bm{D}Dを用いて divD=ρ div \\bm{D} = \\rho divD=ρ と書くこともできます つまり今回は クーロンの法則→電場の式→ガウスの法則→divE=ρε0div\\bm{E}=\\frac{\\rho}{\\varepsilon_0}divE=ε0​ρ​ という式の変化を見ました "},"elec/elec03.html":{"url":"elec/elec03.html","title":"03 Potential","keywords":"","body":"03 Potential "},"dis-math/dis-math00.html":{"url":"dis-math/dis-math00.html","title":"Discrete Math","keywords":"","body":"Discrete Math 情報科学で使われる様々な概念を把握するのに必要となる知識 Set Proof "},"dis-math/dis-math01.html":{"url":"dis-math/dis-math01.html","title":"01 Set","keywords":"","body":"01 Set 集合 集合とは｢順序付けられていない,どんなものでもいい(集合も含めて)異なるものの集まり｣です この｢もの｣を要素と言います 要素にはあらゆるものが成れます 数字だけでなく,人間や植物,惑星も｢もの｣です 集合は外延的記法(set notation)という\"{}\"という要素をくくった書き方で表現できます 外延的記法の例 中括弧(brace),つまり{\\lbrace{と}\\rbrace}で囲みます コンマ(,,,)で区切ります 例:{日本人,田中くん,魚}\\lbrace\\text{日本人}, \\text{田中くん}, \\text{魚}\\rbrace{日本人,田中くん,魚} 集合では同じ要素のことは考慮しません 下の集合は全て,｢焼肉定食｣,｢コンパイラ｣,｢114514｣を含む集合を表しており同じ集合です {焼肉定食,コンパイラ,114514}{コンパイラ,焼肉定食,コンパイラ,114514,114514}{コンパイラ,コンパイラ,コンパイラ,焼肉定食,コンパイラ,114514} \\begin{aligned} &\\lbrace \\text{焼肉定食}, \\text{コンパイラ}, 114514\\rbrace\\\\ &\\lbrace \\text{コンパイラ}, \\text{焼肉定食}, \\text{コンパイラ}, 114514, 114514\\rbrace\\\\ &\\lbrace \\text{コンパイラ}, \\text{コンパイラ}, \\text{コンパイラ}, \\text{焼肉定食}, \\text{コンパイラ}, 114514\\rbrace \\end{aligned} ​{焼肉定食,コンパイラ,114514}{コンパイラ,焼肉定食,コンパイラ,114514,114514}{コンパイラ,コンパイラ,コンパイラ,焼肉定食,コンパイラ,114514}​ 繰り返し出てくる要素は無視されます {1,2,2,2,2}\\lbrace1, 2, 2, 2, 2\\rbrace{1,2,2,2,2}という集合は,{1,2}\\lbrace1, 2\\rbrace{1,2}という集合と同じ集合なのです 集合と要素 空集合とは要素を持たない集合です つまり,{}\\lbrace\\rbrace{}のような集合です.0にスラッシュを付けたような記号で表します {}=∅ \\lbrace\\rbrace = \\emptyset {}=∅ また,集合と要素は区別します 1≠{1} 1 \\ne \\lbrace1\\rbrace 1≠{1} また,集合は集合も要素として持てます 下のように空集合と,空集合を持った集合は等しいのでしょうか? ∅=?{∅} \\emptyset \\overset{?}{=} \\lbrace\\emptyset\\rbrace ∅=?{∅} もちろん違います.∅\\emptyset∅は要素を持たない集合なので,空集合を要素に持つ集合とは等しくありません. よって正しい式は次の通りです ∅≠{∅} \\emptyset \\ne \\lbrace\\emptyset\\rbrace ∅≠{∅} あるもの(aaaとします)がある集合(AAAとします)に入っていることをaaaはAAAに｢属する｣と言います これを式にすると以下の通り a∈A a \\in A a∈A {1,2,3,4,5,6}\\lbrace1,2,3,4,5,6\\rbrace{1,2,3,4,5,6}という集合について考えます この集合に111は属しているでしょうか? もちろん,111は属しています.つまり以下のように書けます 1∈{1,2,3,4,5,6} 1 \\in \\lbrace1,2,3,4,5,6\\rbrace 1∈{1,2,3,4,5,6} では,777はこの集合に属しているのでしょうか? この集合に777はないので属していません よって,次のように書けます 7≠∈{1,2,3,4,5,6} 7 \\ne \\in \\lbrace1,2,3,4,5,6\\rbrace 7≠∈{1,2,3,4,5,6} 有限集合と無限集合 今までは要素が有限な集合について扱っていました ここでは要素の無限に多い集合を扱しています 例えばN={0,1,2,3,..}\\mathbb{N}=\\lbrace0,1,2,3,..\\rbraceN={0,1,2,3,..}は全ての自然数の集合です CSでは自然数に0を含むことが多いのでここでは0を自然数に含めています 英語で自然数はNatural number Z={...,−2,−1,0,1,2,...}\\mathbb{Z}=\\lbrace..., -2, -1,0,1,2,...\\rbraceZ={...,−2,−1,0,1,2,...}は全ての整数の集合です ドイツ語で整数はZahlen(英語ではInteger) 外延的記法では｢全ての自然数の集合｣のような集合を厳密に書けません このような集合を数学的に書くには内包的記法 (set-builder notation)を用います 以下のように内包的記法は書きます {\\lbrace{と∣\\mid∣と}\\rbrace}で区切ります ∣\\mid∣の左側に集合の要素を書きます ∣\\mid∣の右側にその集合の満たす条件を書きます 例:{∣n∈N and n is odd}\\lbrace \\mid n \\in \\mathbb{N} \\text{ and n is odd}\\rbrace{∣n∈N and n is odd} ちなみに∣\\mid∣はLATXE\\LaTeXLATE​Xで書く際は\\midを使います つまり {∣xが満たすある条件} \\lbrace \\mid \\text{xが満たすある条件}\\rbrace {∣xが満たすある条件} という風に書くのが内包的記法です 集合の組み合わせ 集合を組み合わせて,共通する要素などを表現することができます ベン図 ベン図は集合の組み合わせを視覚的に表現したものです 図はこちらで見るといいでしょう 具体的に以下のようなものがあります また,A={1,2,3}A=\\lbrace1,2,3\\rbraceA={1,2,3}, B={3,4,5}B=\\lbrace3,4,5\\rbraceB={3,4,5}とします 和集合(Union)は少なくともどちらかの集合に含まれる要素の集合 A∨B={1,2,3,4,5}A \\lor B = \\lbrace 1,2,3,4,5\\rbraceA∨B={1,2,3,4,5} 共通部分(intersection )はどちらの集合にも含まれる要素の集合 A∧B={3}A \\land B =\\lbrace 3\\rbraceA∧B={3} 差集合(difference)は片方の集合に含まれる要素を抜いた要素の集合 A−B={1,2}A - B=\\lbrace1,2\\rbraceA−B={1,2} もしくは A∖B={1,2}A \\setminus B = \\lbrace1,2\\rbraceA∖B={1,2} 排他的論理和(Symmetric Difference)はどちらの集合にも含まれる要素の集合を和集合から引いたもの AΔB={1,2,4,5}A \\Delta B = \\lbrace1,2,4,5\\rbraceAΔB={1,2,4,5} 部分集合と冪集合 部分集合 もし,集合Aの全ての要素が集合Bの要素でもあるとき,集合Aは集合Tの部分集合 (subset)だと言います A⊆B A \\subseteq B A⊆B ここで注意したいことがあります.S∈TS\\in TS∈TとS⊆TS \\subseteq TS⊆Tの違いです S∈TS \\in TS∈TはSという要素がTに含まれるということを意味しています S⊆TS \\subseteq TS⊆TはSに含まれる全ての要素がTに含まれるということを意味しています このように明確な違いが有ります また,ここで浮かぶ疑問は｢∅はどう扱われるのだろう?｣ということだと思います 実は∅は全ての集合の部分集合なのです PとQがあるとします.Pが何も持っていないとき｢Pが持つ全てのものはQのものでもある｣という命題は真と定義されています これを\"Vacuously true\"であると言います 例えば,彼女がいない人が｢俺の彼女はとてもかわいい｣と言った場合は真です 俺の彼女∈かわいい \\text{俺の彼女} \\in \\text{かわいい} 俺の彼女∈かわいい 同様に∅\\emptyset∅も要素を持たないので,｢全ての集合は∅の要素を含む｣という命題もまた真です 冪集合 冪集合(power set)とはある集合の全ての集合を含む集合のことです.ちなみにべきしゅうごうと呼びます 定義は下の通り ℘(S)={T∣T∈S} \\wp(S) = \\lbrace T \\mid T\\in S\\rbrace ℘(S)={T∣T∈S} 例えば,A={1,2}A = \\lbrace 1,2\\rbraceA={1,2}の冪集合は℘(A)={∅,{1},{2},{1,2}}\\wp(A) = \\lbrace \\emptyset, \\lbrace 1\\rbrace, \\lbrace 2\\rbrace, \\lbrace 1, 2\\rbrace\\rbrace℘(A)={∅,{1},{2},{1,2}}です では∅の冪集合は何でしょうか? ∅ですね 濃度 濃度(cardinality)とは集合の含む要素の数のことです 集合SSSの濃度は∣S∣|S|∣S∣と書きます S={1,2}S = \\lbrace 1, 2\\rbraceS={1,2}のとき,∣S∣=2|S| = 2∣S∣=2ですね 無限集合 ここで問題です 自然数の集合N\\mathbb{N}Nの濃度は一体なんでしょうか 自然数の集合は無限に多くの数を持っています.そのため,自然数ではありません ここで,ℵ0=∣N∣\\aleph_0 = |\\mathbb{N}|ℵ0​=∣N∣とします.読み方は\"aleph-zero\" or \"aleph-nought\" or \"aleph-null\"です 集合の濃度が同じということはどのように定義されているのでしょうか. ｢2つの集合の要素を余らすことなく1組に対応付けられる場合,2つの集合の濃度が等しい｣と定義されています 集合S={n∣n∈N and n is even}S = \\lbrace n \\mid n\\in \\mathbb{N} \\text{ and n is even}\\rbraceS={n∣n∈N and n is even}という集合はn↔2nn \\leftrightarrow 2nn↔2nと対応付ければ自然数の集合N\\mathbb{N}Nと1組に対応付けられます そのため,これらの集合の濃度は同じです また,有理数の集合Z\\mathbb{Z}Zも自然数と濃度は同じです Z\\mathbb{Z}Zの要素が非負数のときN\\mathbb{N}Nの偶数の要素と組付け,Z\\mathbb{Z}Zの要素が負数のとき,N\\mathbb{N}Nの奇数の要素と組み付ければ良いのです カントールの定理 カントールの定理 (Cantor's theorem )とは全ての集合はその冪集合より小さいとする定理です これより,すべて無限集合は同じ大きさではありません つまり,無限に無限に多くの無限集合があるということになります これがどうコンピュータと関係するのか 文字列は文字 (アルファベット･数字･漢字など )からなるものだとします このとき 多くても文字列と同じだけのプログラムがある 少なくとも文字列の集合と同じだけの問題がある ということが言えます コンピュータのソースコードは文字列です.昔はパンチカード,今は高性能のIDEで書かれているかもしれませんが基本は変わっていません そのため,すべてのプログラムは文字列からできており,(1)が成り立ちます すべての問題は文字列の集合からなります 例えば000~999からなる文字列が奇数か偶数か判定するというもの このように問題は文字列の集合からなります.そのため(2)が成り立ちます つまりカントールの定理から以下のようなことが言えるわけです ∣programs∣≤∣string∣≤∣℘(strings)∣≤∣problems∣ |\\text{programs}| \\leq |\\text{string}| \\leq |\\wp(\\text{strings})| \\leq |\\text{problems}| ∣programs∣≤∣string∣≤∣℘(strings)∣≤∣problems∣ そして,コンピュータで解ける問題というのはほとんどないということがわかります そのため,離散数学を使ってこれについて考える必要があるというわけです まとめ 集合は順序の関係の異なる要素が集まったもの 外延的記法と内包的記法がある 空集合は要素を持たない AAAの要素が全てBBBに含まれる時,AAAはBBBの部分集合であると言う ある集合の要素からなる全ての集合からなる集合を冪集合と言う 集合の持つ要素の数を濃度と言う カントールの定理から全ての集合はその冪集合よりも小さい "},"dis-math/dis-math02.html":{"url":"dis-math/dis-math02.html","title":"02 Proof","keywords":"","body":"02 Proof "},"algo/algo00.html":{"url":"algo/algo00.html","title":"Algorithm","keywords":"","body":"Algorithm OS,暗号技術,人工知能,ネットワーク,コンパイラー...などなどあらゆる情報科学の分野で必要となる知識 Order "},"algo/algo01.html":{"url":"algo/algo01.html","title":"Order","keywords":"","body":"Order アルゴリズムを考える際,一つの指標となるのが計算量です 計算量とは空間計算量･時間計算量がありますがどちらも基本となる考え方は同じです ここでは時間計算量について考えます Asymptotic Analysis 計算量とはそのアルゴリズムがどのような関数に漸近するのかを考えたものです そのため,以下のようなメリット･デメリットがあります メリット 環境に依存しないアルゴリズムそのものの良し悪しについて考えられる よりアルゴリズムを取り扱いやすくする デメリット 入力が大きい時しか考慮していない この計算量を求める方法は Tree Method Master Theorem(Generalized Method) Substitution Method 以上の3種類が有ります Tree Methodを一般化したものなので以下ではMaster TheoremとSustitution Method を扱います その前に計算量の記法について学びましょう 計算量記法 ここではBig-O記法･Big-Omega記法･Big-Theta記法について考えます Big-O T(n)T(n)T(n)(計算にかかる時間で,値は正で単調増加だとします)とg(n)g(n)g(n)が正の整数の関数だとします ∃c,n0>0 s.t. ∀n≥n00≤T(n)≤cg(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq T(n) \\leq cg(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤T(n)≤cg(n)​ であるとき,T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))とします ` ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも小さいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の上限であるということです T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))はT(n)=O(g(n))T(n) = O(g(n))T(n)=O(g(n))とも書きます(こう書く場合の方が多いです) Big-Omega Big-O記法は上限を表現するためでしたが,Big-Omega記法は下限を表現するための記法です 上と同じ関数T(n)T(n)T(n)とg(n)g(n)g(n)を用いて ∃c,n0>0 s.t. ∀n≥n00≤cg(n)≤T(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq cg(n) \\leq T(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤cg(n)≤T(n)​ のときT(n)∈Ω(g(n))T(n) \\in \\Omega(g(n))T(n)∈Ω(g(n))もしくはT(n)=Ω(g(n))T(n) = \\Omega(g(n))T(n)=Ω(g(n))とします ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも大きいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の下限であるということです Big-Theta Big-Theta記法は上の記法のどちらもが当てはまるときです つまり,以下の式を満たします ∃c0,c1,n0>0 s.t. ∀n≤n00≤c0⋅g(n)≤f(n)≤c1⋅g(n) \\begin{aligned} \\exists{c_0, c_1, n_0} &> 0 \\text{ s.t. } \\forall{n} \\leq n_0 \\\\ 0 &\\leq c_0 \\cdot g(n) \\leq f(n) \\leq c_1\\cdot g(n) \\end{aligned} ∃c0​,c1​,n0​0​>0 s.t. ∀n≤n0​≤c0​⋅g(n)≤f(n)≤c1​⋅g(n)​ Big-Theta記法は無限に大きいnnnでg(n)g(n)g(n)の定数倍にT(n)T(n)T(n)が挟まれる状態にあるということです Master Theorem 最初に定理を紹介し,あとから説明をします a≥1a\\geq 1a≥1, b≥1b \\geq 1b≥1, dddをnnnに独立な定数とします このときT(n)=a⋅T(nb)+O(nd)T(n)=a \\cdot T(\\frac{n}{b}) + O(n^d)T(n)=a⋅T(bn​)+O(nd)とすると以下の式を満たします T(n)={O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb(a))(a>bd) T(n) = \\begin{cases} O(n^{d}log(n)) (a = b^d) \\\\ O(n^d) (a b^d) \\end{cases} T(n)=⎩⎪⎨⎪⎧​O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb​(a))(a>bd)​ この定理を分類定理(master theorem)と言います aaa : 分割された下位問題の数 bbb : 入力の大きさが縮む倍率(2→12 \\rightarrow 12→1のときはb=2b=2b=2) ddd : 全ての問題を分割し統合するのに必要な計算量 この定理は問題を分割し,それらを更に分割し解くという考えを使っています(これを再帰と言います) 入力がnnnの問題をT(n)T(n)T(n)で解くアルゴリズムを考えます 入力nnnをaaa個に分割する 分割された入力をT(nb)T(\\frac{n}{b})T(bn​)で解く 分割された各アルゴリズムに対してかかる時間が(O(nlog⁡b(a))(O(n^{\\log_{b}(a)})(O(nlogb​(a))である このようにするとT(n)T(n)T(n)は上のような式になります.実際にそれぞれのケースごとに正しいか確認してみましょう a=bda=b^da=bdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t=c⋅nd⋅∑t=0log⁡b(n)1=c⋅nd⋅(log⁡b(n)+1)=c⋅nd⋅(log⁡(n)log⁡(b)+1)=O(ndlog⁡(n)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t \\\\ &= c \\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}1 \\\\ &= c \\cdot n^d \\cdot (\\log_b(n) + 1) \\\\ &= c \\cdot n^d \\cdot (\\frac{\\log(n)}{\\log(b)} + 1) \\\\ &= O(n^d \\log(n)) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t=c⋅nd⋅t=0∑logb​(n)​1=c⋅nd⋅(logb​(n)+1)=c⋅nd⋅(log(b)log(n)​+1)=O(ndlog(n))​ abda abdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満 T(n) = c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} T(n)=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​ ここで,等比級数の和は一般項xxxが1より大きい時は次数が最大の項が支配的になり,xxxが0より大きく1より小さい時は次数が最小の項が支配的になる ここでは∑t=0log⁡b(n)(abd)t\\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t∑t=0logb​(n)​(bda​)tの一般項は後者なので定数として扱える T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満=c⋅nd⋅定数=O(nd) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} \\\\ &= c \\cdot n^d \\cdot \\text{定数} \\\\ &= O(n^d) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​=c⋅nd⋅定数=O(nd)​ a>bda > b^da>bdの場合 上の例で扱ったように一般項に注目する T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1より大きい=O(nd(abdlogb(n)))=O(nlog⁡b(a)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{より大きい}} \\\\ &=O(n^d(\\frac{a}{b^d}^{log_b(n)})) \\\\ &=O(n^{\\log_b(a)}) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1より大きい​=O(nd(bda​logb​(n)))=O(nlogb​(a))​ Substitution Method これは以下の手順から成り立ちます 答えを推論する その推論が正しいと証明する 答えを得る 例 T(n)=2⋅T(n2)+nT(n) = 2 \\cdot T(\\frac{n}{2}) + nT(n)=2⋅T(2n​)+nという例をここでは扱います(ただしT(1)=1T(1)=1T(1)=1). 推論 この時,実際に手を動かしてみると T(n)=2⋅T(n2)+n=2⋅(2⋅T(n4)+n2)+n=4⋅T(n4)+2n=4⋅T(2⋅T(n8)+n4)+2n=8⋅T(n8)+3n=⋯ \\begin{aligned} T(n) &= 2 \\cdot T(\\frac{n}{2}) + n \\\\ &=2 \\cdot (2 \\cdot T(\\frac{n}{4}) + \\frac{n}{2}) + n \\\\ &= 4 \\cdot T(\\frac{n}{4}) + 2n \\\\ &= 4 \\cdot T(2 \\cdot T(\\frac{n}{8}) + \\frac{n}{4}) + 2n \\\\ &= 8 \\cdot T(\\frac{n}{8}) + 3n &= \\cdots \\end{aligned} T(n)​=2⋅T(2n​)+n=2⋅(2⋅T(4n​)+2n​)+n=4⋅T(4n​)+2n=4⋅T(2⋅T(8n​)+4n​)+2n=8⋅T(8n​)+3n​=⋯​ このようになり, T(n)=2t⋅T(n2t)+t⋅nT(n) = 2^t \\cdot T(\\frac{n}{2^t})+ t\\cdot nT(n)=2t⋅T(2tn​)+t⋅nになるのではないかと推測できます t=log(n)t=log(n)t=log(n)を代入し, T(n)=n⋅T(1)+log⁡(n)⋅(n)⋅n=n(log⁡(n)+1) T(n)= n \\cdot T(1) + \\log(n) \\cdot(n) \\cdot n = n(\\log(n) + 1) T(n)=n⋅T(1)+log(n)⋅(n)⋅n=n(log(n)+1) と推論できます 証明 数学的帰納法で証明します Inductive Hypothesis T(j)=j(log⁡(j)+1)T(j) = j(\\log(j)+1)T(j)=j(log(j)+1)が1≤j≤n1 \\leq j \\leq n1≤j≤nで成り立つと仮定します Base Case(n=1n=1n=1) T(1)=1=1⋅(log⁡(1)+1)T(1) = 1 = 1 \\cdot (\\log(1) + 1)T(1)=1=1⋅(log(1)+1)となり成り立ちます Inductive Step inductive hypothesisがn=k−1n=k-1n=k−1で成り立つと仮定します このとき定義からT(k)=2⋅T(k2)+kT(k)= 2 \\cdot T(\\frac{k}{2}) + kT(k)=2⋅T(2k​)+kであり,仮定よりT(k)=2⋅(k2(log⁡(k2)+1))+kT(k)= 2 \\cdot (\\frac{k}{2}(\\log(\\frac{k}{2})+1))+kT(k)=2⋅(2k​(log(2k​)+1))+kです.簡単にすると, T(k)=k(log⁡(k)+2) T(k)=k (\\log(k) + 2) T(k)=k(log(k)+2) となり,n=kn=kn=kでも成り立つことが示されました 結論 n≥1n \\geq 1n≥1 で T(n)=n(log⁡(n)+1)T(n) = n(\\log(n) + 1)T(n)=n(log(n)+1)とわかります このように事前の推論を数学的帰納法で証明することをSubstituion Methodと言います まとめ 計算量という概念を導入することでアルゴリズムの良し悪しが分かる 計算量を導く方法がある "},"comp-arch/comp-arch00.html":{"url":"comp-arch/comp-arch00.html","title":"Computer Architecture","keywords":"","body":"Computer Architecture "},"clang/clang00.html":{"url":"clang/clang00.html","title":"C Language","keywords":"","body":"C Language "},"clang/clang01.html":{"url":"clang/clang01.html","title":"01 Introduction to C","keywords":"","body":"01 Introduction to C "},"info-theo/info-theo00.html":{"url":"info-theo/info-theo00.html","title":"Information theory","keywords":"","body":"Information theory 情報理論とは情報を数量的に捉える理論のことです Entropy Information Resource "},"info-theo/info-theo01.html":{"url":"info-theo/info-theo01.html","title":"01 Entropy","keywords":"","body":"01 Entropy "},"info-theo/info-theo02.html":{"url":"info-theo/info-theo02.html","title":"02 Information Resource","keywords":"","body":"02 Information Resource "},"info-geo/info-geo00.html":{"url":"info-geo/info-geo00.html","title":"Information geometry","keywords":"","body":"Information geometry "},"os/os00.html":{"url":"os/os00.html","title":"Operating system","keywords":"","body":"Operating system "},"os/os01.html":{"url":"os/os01.html","title":"01 Introduction to OS","keywords":"","body":"01 Introduction to OS "},"os/os02.html":{"url":"os/os02.html","title":"02 Thread & Process","keywords":"","body":"02 Thread & Process "},"os/os03.html":{"url":"os/os03.html","title":"03 C & Assembly","keywords":"","body":"03 C & Assembly "},"other/editor.html":{"url":"other/editor.html","title":"Editor","keywords":"","body":"Editor "},"other/latex.html":{"url":"other/latex.html","title":"Latex","keywords":"","body":"Latex "},"other/git.html":{"url":"other/git.html","title":"Git","keywords":"","body":"Git "}}