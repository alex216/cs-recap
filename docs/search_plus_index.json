{"./":{"url":"./","title":"Computer Science Recapitulaion","keywords":"","body":"CS Recap ここではComputer Scienceに関連する分野で自分が勉強した内容を書いていきます 間違った内容などがあったら是非青い鳥にDM or リプライをするかプルリクエストをして下さい 文中ではOSをUbuntu(18.04以降)かMac OSを(Mojave以降)を想定しています 内容に関する注意 本文に従って何かしらの不利益を被った際の責任は取りませんのであしからず Core CSの基礎となるような内容です Math Calculus Linear algebra Statistics Set & Topology Physics Electromagnetics CS Discrete math Algorithm Computer architecture Signal processing C language Selective Coreの内容を土台とする発展的な内容です Information theory Operating system Other topics 関連した内容です Editor Latex Git 編集について About editing this site "},"cal/cal00.html":{"url":"cal/cal00.html","title":"Calculus","keywords":"","body":"Calculus "},"linear-alge/linear-alge00.html":{"url":"linear-alge/linear-alge00.html","title":"Linear algebra","keywords":"","body":"Linear algebra "},"stat/stat00.html":{"url":"stat/stat00.html","title":"Statistics","keywords":"","body":"Statistics "},"set-topology/set-phase00.html":{"url":"set-topology/set-phase00.html","title":"Set & Topology","keywords":"","body":"Set & Topology "},"elec/elec00.html":{"url":"elec/elec00.html","title":"Electromagnetics","keywords":"","body":"Electromagnetics 多くのコンピュータの動力源である電気と磁気についての理論 Basic Math Coulomb & Gaussian Potential "},"elec/elec01.html":{"url":"elec/elec01.html","title":"01 Basic Math","keywords":"","body":"01 Basic Math 電磁気で用いる数学についてやります ベクトル解析 電磁気では多くの数学が使われます ここではそのうち最も重要であるベクトル解析について簡単に触れます スカラー積とベクトル積 スカラー積は内積,ベクトル積は外積とも呼びます ベクトルA\\bm{A}AとベクトルB\\bm{B}Bのスカラー積とは,A\\bm{A}Aの大きさにB\\bm{B}BのA\\bm{A}Aのに落とした正射影の成分の大きさをかけたものです 式では次のように書きます A⋅B=∣A∣∣B∣cos⁡θ \\bm{A} \\cdot \\bm{B} = |A||B|\\cos\\theta A⋅B=∣A∣∣B∣cosθ また A⋅B=AxBx+AyBy \\bm{A} \\cdot \\bm{B} = A_x B_x + A_y B_y A⋅B=Ax​Bx​+Ay​By​ となるのも,AxByA_x B_yAx​By​などが直行してxxx軸に対して(もしくはy軸に対して)大きさがないからです ベクトル積は回転が関係します ベクトルrrrとベクトルFFFのベクトル積はrrrからFFFにひねった方向に回転し,それに対する右ねじの方向に向いた力です 例えばxxx, yyy, zzz軸方向に大きさ1の単位ベクトルがあるとして xxx同士の掛け算は回転しないので大きさ000のベクトル xxxとyyyの掛け算は回転するので大きさ111のzzz方向へのベクトル yyyとxxxの掛け算は回転するので大きさ111の−z-z−z方向へのベクトル 微分 偏微分 偏微分は変数を定数として見るというものです 偏微分は∂\\partial∂を使って演算をします おそらく問題ないと思います 全微分 全微分は以下のような式です Δf=∂f∂xΔx+∂f∂yΔy+∂f∂zΔz \\Delta f = \\frac{\\partial f}{\\partial x}\\Delta x + \\frac{\\partial f}{\\partial y}\\Delta y + \\frac{\\partial f}{\\partial z}\\Delta z Δf=∂x∂f​Δx+∂y∂f​Δy+∂z∂f​Δz この数式がどのようなイメージを持つかを説明するため,x−yx-yx−yの2次元に次元を落として考えます 場の量fffはx−yx-yx−y平面上で定義された量でかつスカラーとしておけばx−yx-yx−y平面上を覆うような曲面だということがわかると思います この微小な領域を考えます その微小な領域のxxx, yyy方向での変化をそれぞれΔx\\Delta xΔx, Δy\\Delta yΔyとすると,zzz軸方向の変化は∂f∂yΔy+∂f∂xΔx\\frac{\\partial f}{\\partial y}\\Delta y + \\frac{\\partial f}{\\partial x}\\Delta x∂y∂f​Δy+∂x∂f​Δx つまり,全微分とはそのような微小な領域の体積を求めているのです ∇\\nabla∇関連の公式の意味 gradψ\\psiψ(∇ψ\\nabla \\psi∇ψ) スカラー場ψ\\psiψから傾斜を求めるときに使うのがgradψgrad \\psigradψ(∇ψ\\nabla \\psi∇ψ)です これも全微分の例と同様に考えることが可能です つまり,スカラー場ψ\\psiψの最大傾斜の方向を向き,傾斜が大きければ大きいほどその値も大きなベクトルです divAdiv AdivA(∇A\\nabla A∇A) 具体的に divD=ρ div \\bm{D} = \\rho divD=ρ を考えてみます この式の両辺に微小体積ΔV\\Delta VΔVをかけるとh divDΔV=ρΔV div \\bm{D} \\Delta V = \\rho \\Delta V divDΔV=ρΔV 右辺はρ\\rhoρを電荷密度としてその体積の中にある電気量の合計です divDΔV=(∂Dx∂x+∂Dy∂y+∂Dz∂z)ΔxΔyΔz div \\bm{D} \\Delta V = \\left( \\frac{\\partial D_x}{\\partial x} + \\frac{\\partial D_y}{\\partial y} + \\frac{\\partial D_z}{\\partial z} \\right) \\Delta x \\Delta y \\Delta z divDΔV=(∂x∂Dx​​+∂y∂Dy​​+∂z∂Dz​​)ΔxΔyΔz ここで∂Dx/∂x\\partial D_x / \\partial x∂Dx​/∂xだけを考えます ∂Dx∂xΔxΔyΔz=∂Dx∂xΔx⋅ΔyΔz \\frac{\\partial D_x}{\\partial x}\\Delta x \\Delta y \\Delta z = \\frac{\\partial D_x}{\\partial x}\\Delta x \\cdot \\Delta y \\Delta z ∂x∂Dx​​ΔxΔyΔz=∂x∂Dx​​Δx⋅ΔyΔz となります.このとき∂Dx∂x\\frac{\\partial D_x}{\\partial x}∂x∂Dx​​はΔx\\Delta xΔxだけ変化したDxD_xDx​の増加分なので次のように書けます ∂Dx∂xΔx⋅ΔyΔz=Δx(x+Δx)−Δx(x)ΔyΔz \\frac{\\partial D_x}{\\partial x}\\Delta x \\cdot \\Delta y \\Delta z = { \\Delta_x (x + \\Delta x) - \\Delta_x(x)} \\Delta y \\Delta z ∂x∂Dx​​Δx⋅ΔyΔz=Δx​(x+Δx)−Δx​(x)ΔyΔz つまり,微小な面を通過する電束の差分です この値を積分すると体積全体から出てくる電束を求めることができます.よって ∫VdivDdV=∫SD⋅dS \\int_V div \\bm{D} dV = \\int_S \\bm{D} \\cdot dS ∫V​divDdV=∫S​D⋅dS という書くことができます.Δ\\DeltaΔを電束密度に限らず,任意のベクトルにするとA\\bm{A}Aと書け, ∫VdivAdV=∫SA⋅ndS \\int_V div \\bm{A} dV = \\int_S \\bm{A} \\cdot \\bm{n} dS ∫V​divAdV=∫S​A⋅ndS と書くことができます.これは体積積分とその表面の面積積分の関係を示す公式でガウスの定理と言います(電磁気の場合はガウスの法則) rotArot ArotA(∇×A\\nabla \\times A∇×A) これは回転のイメージです ここでもΔx\\Delta xΔxに関してだけ見ると計算結果は (∂Ay∂x−∂Ax∂y)ΔxΔy \\left( \\frac{\\partial A_y}{\\partial x} - \\frac{\\partial A_x}{\\partial y} \\right) \\Delta x \\Delta y (∂x∂Ay​​−∂y∂Ax​​)ΔxΔy となります.これは 回転の効果を足したもの=(Δ×A大きさ×(経路で囲まれる面積)) \\text{回転の効果を足したもの} = (\\Delta \\times \\bm{A}\\text{大きさ} \\times (\\text{経路で囲まれる面積})) 回転の効果を足したもの=(Δ×A大きさ×(経路で囲まれる面積)) という意味を持ちます.つまりこの値に対して線積分をすれば ∮CA⋅ds=∫s(Δ×A)n⋅dS \\oint_C \\bm{A} \\cdot d\\bm{s} = \\int_s (\\Delta \\times \\bm{A})_n \\cdot dS ∮C​A⋅ds=∫s​(Δ×A)n​⋅dS これがストークスの定理です ガウスの定理は体積積分と面積分の関係ですが,ストークスの定理は線積分と面積積分の関係です ラプラシアン(∇⋅(∇ψ)\\nabla \\cdot (\\nabla \\psi )∇⋅(∇ψ)) gradのdivdivdivです ∇×(∇ψ)=0\\nabla \\times (\\nabla \\psi) = 0∇×(∇ψ)=0 ∇\\nabla∇を掛けた(grad)場合,xxx成分にはyyy成分とzzz成分のみしかないので,それに∇\\nabla∇をベクトル積したもの(rot)は当然000のベクトルとなります ∇⋅(∇×A)=0\\nabla \\cdot (\\nabla \\times A) = 0∇⋅(∇×A)=0 これも上と変わりません 物理的なイメージを考えれば当然の式です "},"elec/elec02.html":{"url":"elec/elec02.html","title":"02 Coulomb & Gaussian","keywords":"","body":"02 Coulomb & Gaussian クーロンの法則 2つの点電荷の間にどのような力が働くかを示す法則です 電気量q1q_1q1​の点電荷AAAと電気量q2q_2q2​の点電荷BBBがあるとして,その距離がrrrのとき,その間に働くクーロン力(静電気力)の大きさFFFは F=kq1q2r F = k \\frac{q_1 q_2}{r} F=krq1​q2​​ ただし,k=14πε0k = \\frac{1}{4 \\pi \\varepsilon_0}k=4πε0​1​は比例定数です またAAAがBBBから受け取るクーロン力は FAB=14πε0q1q2r3r F_{\\bm{A}\\bm{B}} = \\frac{1}{4\\pi \\varepsilon_0}\\frac{q_1 q_2}{r^3}\\bm{r} FAB​=4πε0​1​r3q1​q2​​r と表せます 電場 電場とは点電荷から湧き出るエネルギーのようなものです クーロンの法則から電場は E=q4πε0r2n \\bm{E} = \\frac{q}{4 \\pi \\varepsilon_0 r^2}\\bm{n} E=4πε0​r2q​n と定義できます それを電気力線という架空の存在で表現します.わかりやすく1クーロンで1本という風に決めます このとき,あるq(>0)q(>0)q(>0)の電気量を持った点電荷からqqq本の電気力線が湧き出ています.点電荷を中心とした球面の表面積は4πr24\\pi r^24πr2なので球面上での電気力線の密度DDDは D=q4πr2 D = \\frac{q}{4 \\pi r^2} D=4πr2q​ ベクトルで表現すると(n\\bm{n}nは球の中心から外側に向かう単位ベクトル) D=q4πr2n D = \\frac{q}{4 \\pi r^2}\\bm{n} D=4πr2q​n 電気力線の密度は電束密度と呼び,電気力線のことは電束と呼びます ここで電束密度の式とクーロンの法則で定義した電場の式を比べる.すると両者の違いは1/ε01 / \\varepsilon_01/ε0​しかないことがわかります この違いは単位を揃えるための便宜的なものです ここでは電気量qqqの点電荷から生じる電気力線の本数を電束密度と電場の単位を揃えるためにq/ε0q / \\varepsilon_0q/ε0​とします ガウスの法則 点電荷を囲む球面から通って出ていく電気力線の本数は点電荷の持つ電気量(÷ε0\\div \\varepsilon_0÷ε0​)に等しいというのは直感的に理解できます この関係を式で表すのがガウスの法則です 電気力線が面を直角に通過する時はその本数は｢電場(電気力線の密度) ×\\times× 面積｣ですが,斜めに通過する可能性もあります 通過する面積は実質的にはdScos⁡θdS\\cos \\thetadScosθとなっているので,面に対する単位法線ベクトルn\\bm{n}nを用いて ∫SE⋅ndS=qε0 \\int_S \\bm{E} \\cdot \\bm{n} dS = \\frac{q}{\\varepsilon_0} ∫S​E⋅ndS=ε0​q​ と表わせ,これがガウスの法則です 左辺はガウスの定理によって ∫SE⋅ndS=∫VdivEdV \\int_S \\bm{E} \\cdot \\bm{n} dS = \\int_V div \\bm{E} dV ∫S​E⋅ndS=∫V​divEdV となります 左辺は｢電気力線の密度と面積｣から求めた電気量です.右辺は｢電気力線の湧き出しと体積｣から求めた電気量です そこで微小な領域dVdVdVで電場の式は divEdV=qε0 div \\bm{E}dV = \\frac{q}{\\varepsilon_0} divEdV=ε0​q​ 確認ですがqε0\\frac{q}{\\varepsilon_0}ε0​q​は電気力線の数です ここで,微小領域に存在する電荷の密度[C/m3][C/m^3][C/m3]を ρ=qdV \\rho = \\frac{q}{dV} ρ=dVq​ とすれば divE=ρε0 div\\bm{E} = \\frac{\\rho}{\\varepsilon_0} divE=ε0​ρ​ となります.これはマクスウェル方程式の1つです これを電解密度D\\bm{D}Dを用いて divD=ρ div \\bm{D} = \\rho divD=ρ と書くこともできます つまり今回は クーロンの法則→電場の式→ガウスの法則→divE=ρε0div\\bm{E}=\\frac{\\rho}{\\varepsilon_0}divE=ε0​ρ​ という式の変化を見ました "},"elec/elec03.html":{"url":"elec/elec03.html","title":"03 Potential","keywords":"","body":"03 Potential "},"dis-math/dis-math00.html":{"url":"dis-math/dis-math00.html","title":"Discrete math","keywords":"","body":"Discrete math 情報科学で使われる様々な概念を把握するのに必要となる知識 Set Proof "},"dis-math/dis-math01.html":{"url":"dis-math/dis-math01.html","title":"01 Set","keywords":"","body":"01 Set 集合 集合とは｢順序付けられていない,どんなものでもいい(集合も含めて)異なるものの集まり｣です この｢もの｣を要素と言います 要素にはあらゆるものが成れます 数字だけでなく,人間や植物,惑星も｢もの｣です 集合は外延的記法(set notation)という\"{}\"という要素をくくった書き方で表現できます 外延的記法の例 中括弧(brace),つまり{\\lbrace{と}\\rbrace}で囲みます コンマ(,,,)で区切ります 例:{日本人,田中くん,魚}\\lbrace\\text{日本人}, \\text{田中くん}, \\text{魚}\\rbrace{日本人,田中くん,魚} 集合では同じ要素のことは考慮しません 下の集合は全て,｢焼肉定食｣,｢コンパイラ｣,｢114514｣を含む集合を表しており同じ集合です {焼肉定食,コンパイラ,114514}{コンパイラ,焼肉定食,コンパイラ,114514,114514}{コンパイラ,コンパイラ,コンパイラ,焼肉定食,コンパイラ,114514} \\begin{aligned} &\\lbrace \\text{焼肉定食}, \\text{コンパイラ}, 114514\\rbrace\\\\ &\\lbrace \\text{コンパイラ}, \\text{焼肉定食}, \\text{コンパイラ}, 114514, 114514\\rbrace\\\\ &\\lbrace \\text{コンパイラ}, \\text{コンパイラ}, \\text{コンパイラ}, \\text{焼肉定食}, \\text{コンパイラ}, 114514\\rbrace \\end{aligned} ​{焼肉定食,コンパイラ,114514}{コンパイラ,焼肉定食,コンパイラ,114514,114514}{コンパイラ,コンパイラ,コンパイラ,焼肉定食,コンパイラ,114514}​ 繰り返し出てくる要素は無視されます {1,2,2,2,2}\\lbrace1, 2, 2, 2, 2\\rbrace{1,2,2,2,2}という集合は,{1,2}\\lbrace1, 2\\rbrace{1,2}という集合と同じ集合なのです 集合と要素 空集合とは要素を持たない集合です つまり,{}\\lbrace\\rbrace{}のような集合です.0にスラッシュを付けたような記号で表します {}=∅ \\lbrace\\rbrace = \\emptyset {}=∅ また,集合と要素は区別します 1≠{1} 1 \\ne \\lbrace1\\rbrace 1≠{1} また,集合は集合も要素として持てます 下のように空集合と,空集合を持った集合は等しいのでしょうか? ∅=?{∅} \\emptyset \\overset{?}{=} \\lbrace\\emptyset\\rbrace ∅=?{∅} もちろん違います.∅\\emptyset∅は要素を持たない集合なので,空集合を要素に持つ集合とは等しくありません. よって正しい式は次の通りです ∅≠{∅} \\emptyset \\ne \\lbrace\\emptyset\\rbrace ∅≠{∅} あるもの(aaaとします)がある集合(AAAとします)に入っていることをaaaはAAAに｢属する｣と言います これを式にすると以下の通り a∈A a \\in A a∈A {1,2,3,4,5,6}\\lbrace1,2,3,4,5,6\\rbrace{1,2,3,4,5,6}という集合について考えます この集合に111は属しているでしょうか? もちろん,111は属しています.つまり以下のように書けます 1∈{1,2,3,4,5,6} 1 \\in \\lbrace1,2,3,4,5,6\\rbrace 1∈{1,2,3,4,5,6} では,777はこの集合に属しているのでしょうか? この集合に777はないので属していません よって,次のように書けます 7≠∈{1,2,3,4,5,6} 7 \\ne \\in \\lbrace1,2,3,4,5,6\\rbrace 7≠∈{1,2,3,4,5,6} 有限集合と無限集合 今までは要素が有限な集合について扱っていました ここでは要素の無限に多い集合を扱しています 例えばN={0,1,2,3,..}\\mathbb{N}=\\lbrace0,1,2,3,..\\rbraceN={0,1,2,3,..}は全ての自然数の集合です CSでは自然数に0を含むことが多いのでここでは0を自然数に含めています 英語で自然数はNatural number Z={...,−2,−1,0,1,2,...}\\mathbb{Z}=\\lbrace..., -2, -1,0,1,2,...\\rbraceZ={...,−2,−1,0,1,2,...}は全ての整数の集合です ドイツ語で整数はZahlen(英語ではInteger) 外延的記法では｢全ての自然数の集合｣のような集合を厳密に書けません このような集合を数学的に書くには内包的記法 (set-builder notation)を用います 以下のように内包的記法は書きます {\\lbrace{と∣\\mid∣と}\\rbrace}で区切ります ∣\\mid∣の左側に集合の要素を書きます ∣\\mid∣の右側にその集合の満たす条件を書きます 例:{∣n∈N and n is odd}\\lbrace \\mid n \\in \\mathbb{N} \\text{ and n is odd}\\rbrace{∣n∈N and n is odd} ちなみに∣\\mid∣はLATXE\\LaTeXLATE​Xで書く際は\\midを使います つまり {∣xが満たすある条件} \\lbrace \\mid \\text{xが満たすある条件}\\rbrace {∣xが満たすある条件} という風に書くのが内包的記法です 集合の組み合わせ 集合を組み合わせて,共通する要素などを表現することができます ベン図 ベン図は集合の組み合わせを視覚的に表現したものです 図はこちらで見るといいでしょう 具体的に以下のようなものがあります また,A={1,2,3}A=\\lbrace1,2,3\\rbraceA={1,2,3}, B={3,4,5}B=\\lbrace3,4,5\\rbraceB={3,4,5}とします 和集合(Union)は少なくともどちらかの集合に含まれる要素の集合 A∨B={1,2,3,4,5}A \\lor B = \\lbrace 1,2,3,4,5\\rbraceA∨B={1,2,3,4,5} 共通部分(intersection )はどちらの集合にも含まれる要素の集合 A∧B={3}A \\land B =\\lbrace 3\\rbraceA∧B={3} 差集合(difference)は片方の集合に含まれる要素を抜いた要素の集合 A−B={1,2}A - B=\\lbrace1,2\\rbraceA−B={1,2} もしくは A∖B={1,2}A \\setminus B = \\lbrace1,2\\rbraceA∖B={1,2} 排他的論理和(Symmetric Difference)はどちらの集合にも含まれる要素の集合を和集合から引いたもの AΔB={1,2,4,5}A \\Delta B = \\lbrace1,2,4,5\\rbraceAΔB={1,2,4,5} 部分集合と冪集合 部分集合 もし,集合Aの全ての要素が集合Bの要素でもあるとき,集合Aは集合Tの部分集合 (subset)だと言います A⊆B A \\subseteq B A⊆B ここで注意したいことがあります.S∈TS\\in TS∈TとS⊆TS \\subseteq TS⊆Tの違いです S∈TS \\in TS∈TはSという要素がTに含まれるということを意味しています S⊆TS \\subseteq TS⊆TはSに含まれる全ての要素がTに含まれるということを意味しています このように明確な違いが有ります また,ここで浮かぶ疑問は｢∅はどう扱われるのだろう?｣ということだと思います 実は∅は全ての集合の部分集合なのです PとQがあるとします.Pが何も持っていないとき｢Pが持つ全てのものはQのものでもある｣という命題は真と定義されています これを\"Vacuously true\"であると言います 例えば,彼女がいない人が｢俺の彼女はとてもかわいい｣と言った場合は真です 俺の彼女∈かわいい \\text{俺の彼女} \\in \\text{かわいい} 俺の彼女∈かわいい 同様に∅\\emptyset∅も要素を持たないので,｢全ての集合は∅の要素を含む｣という命題もまた真です 冪集合 冪集合(power set)とはある集合の全ての集合を含む集合のことです.ちなみにべきしゅうごうと呼びます 定義は下の通り ℘(S)={T∣T∈S} \\wp(S) = \\lbrace T \\mid T\\in S\\rbrace ℘(S)={T∣T∈S} 例えば,A={1,2}A = \\lbrace 1,2\\rbraceA={1,2}の冪集合は℘(A)={∅,{1},{2},{1,2}}\\wp(A) = \\lbrace \\emptyset, \\lbrace 1\\rbrace, \\lbrace 2\\rbrace, \\lbrace 1, 2\\rbrace\\rbrace℘(A)={∅,{1},{2},{1,2}}です では∅の冪集合は何でしょうか? ∅ですね 濃度 濃度(cardinality)とは集合の含む要素の数のことです 集合SSSの濃度は∣S∣|S|∣S∣と書きます S={1,2}S = \\lbrace 1, 2\\rbraceS={1,2}のとき,∣S∣=2|S| = 2∣S∣=2ですね 無限集合 ここで問題です 自然数の集合N\\mathbb{N}Nの濃度は一体なんでしょうか 自然数の集合は無限に多くの数を持っています.そのため,自然数ではありません ここで,ℵ0=∣N∣\\aleph_0 = |\\mathbb{N}|ℵ0​=∣N∣とします.読み方は\"aleph-zero\" or \"aleph-nought\" or \"aleph-null\"です 集合の濃度が同じということはどのように定義されているのでしょうか. ｢2つの集合の要素を余らすことなく1組に対応付けられる場合,2つの集合の濃度が等しい｣と定義されています 集合S={n∣n∈N and n is even}S = \\lbrace n \\mid n\\in \\mathbb{N} \\text{ and n is even}\\rbraceS={n∣n∈N and n is even}という集合はn↔2nn \\leftrightarrow 2nn↔2nと対応付ければ自然数の集合N\\mathbb{N}Nと1組に対応付けられます そのため,これらの集合の濃度は同じです また,有理数の集合Z\\mathbb{Z}Zも自然数と濃度は同じです Z\\mathbb{Z}Zの要素が非負数のときN\\mathbb{N}Nの偶数の要素と組付け,Z\\mathbb{Z}Zの要素が負数のとき,N\\mathbb{N}Nの奇数の要素と組み付ければ良いのです カントールの定理 カントールの定理 (Cantor's theorem )とは全ての集合はその冪集合より小さいとする定理です これより,すべて無限集合は同じ大きさではありません つまり,無限に無限に多くの無限集合があるということになります これがどうコンピュータと関係するのか 文字列は文字 (アルファベット･数字･漢字など )からなるものだとします このとき 多くても文字列と同じだけのプログラムがある 少なくとも文字列の集合と同じだけの問題がある ということが言えます コンピュータのソースコードは文字列です.昔はパンチカード,今は高性能のIDEで書かれているかもしれませんが基本は変わっていません そのため,すべてのプログラムは文字列からできており,(1)が成り立ちます すべての問題は文字列の集合からなります 例えば000~999からなる文字列が奇数か偶数か判定するというもの このように問題は文字列の集合からなります.そのため(2)が成り立ちます つまりカントールの定理から以下のようなことが言えるわけです ∣programs∣≤∣string∣≤∣℘(strings)∣≤∣problems∣ |\\text{programs}| \\leq |\\text{string}| \\leq |\\wp(\\text{strings})| \\leq |\\text{problems}| ∣programs∣≤∣string∣≤∣℘(strings)∣≤∣problems∣ そして,コンピュータで解ける問題というのはほとんどないということがわかります そのため,離散数学を使ってこれについて考える必要があるというわけです まとめ 集合は順序の関係の異なる要素が集まったもの 外延的記法と内包的記法がある 空集合は要素を持たない AAAの要素が全てBBBに含まれる時,AAAはBBBの部分集合であると言う ある集合の要素からなる全ての集合からなる集合を冪集合と言う 集合の持つ要素の数を濃度と言う カントールの定理から全ての集合はその冪集合よりも小さい "},"dis-math/dis-math02.html":{"url":"dis-math/dis-math02.html","title":"02 Proof","keywords":"","body":"02 Proof "},"algo/algo00.html":{"url":"algo/algo00.html","title":"Algorithm","keywords":"","body":"Algorithm OS,暗号技術,人工知能,ネットワーク,コンパイラー...などなどあらゆる情報科学の分野で必要となる知識 Order "},"algo/algo01.html":{"url":"algo/algo01.html","title":"01 Order","keywords":"","body":"Order アルゴリズムを考える際,一つの指標となるのが計算量です 計算量とは空間計算量･時間計算量がありますがどちらも基本となる考え方は同じです ここでは時間計算量について考えます Asymptotic Analysis 計算量とはそのアルゴリズムがどのような関数に漸近するのかを考えたものです そのため,以下のようなメリット･デメリットがあります メリット 環境に依存しないアルゴリズムそのものの良し悪しについて考えられる よりアルゴリズムを取り扱いやすくする デメリット 入力が大きい時しか考慮していない この計算量を求める方法は Tree Method Master Theorem(Generalized Method) Substitution Method 以上の3種類が有ります Tree Methodを一般化したものなので以下ではMaster TheoremとSustitution Method を扱います その前に計算量の記法について学びましょう 計算量記法 ここではBig-O記法･Big-Omega記法･Big-Theta記法について考えます Big-O T(n)T(n)T(n)(計算にかかる時間で,値は正で単調増加だとします)とg(n)g(n)g(n)が正の整数の関数だとします ∃c,n0>0 s.t. ∀n≥n00≤T(n)≤cg(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq T(n) \\leq cg(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤T(n)≤cg(n)​ であるとき,T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))とします ` ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも小さいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の上限であるということです T(n)∈O(g(n))T(n) \\in O(g(n))T(n)∈O(g(n))はT(n)=O(g(n))T(n) = O(g(n))T(n)=O(g(n))とも書きます(こう書く場合の方が多いです) Big-Omega Big-O記法は上限を表現するためでしたが,Big-Omega記法は下限を表現するための記法です 上と同じ関数T(n)T(n)T(n)とg(n)g(n)g(n)を用いて ∃c,n0>0 s.t. ∀n≥n00≤cg(n)≤T(n) \\begin{aligned} &\\exists{c, n_0} > 0 \\text{ s.t. } \\forall{n} \\geq n_0 \\\\ &0 \\leq cg(n) \\leq T(n) \\end{aligned} ​∃c,n0​>0 s.t. ∀n≥n0​0≤cg(n)≤T(n)​ のときT(n)∈Ω(g(n))T(n) \\in \\Omega(g(n))T(n)∈Ω(g(n))もしくはT(n)=Ω(g(n))T(n) = \\Omega(g(n))T(n)=Ω(g(n))とします ある000より大きいn0n_0n0​以上のnnnでは,常にT(n)T(n)T(n)はg(n)g(n)g(n)の定数倍よりも大きいということです つまり,無限に大きいnnnでg(n)g(n)g(n)はT(n)T(n)T(n)の下限であるということです Big-Theta Big-Theta記法は上の記法のどちらもが当てはまるときです つまり,以下の式を満たします ∃c0,c1,n0>0 s.t. ∀n≤n00≤c0⋅g(n)≤f(n)≤c1⋅g(n) \\begin{aligned} \\exists{c_0, c_1, n_0} &> 0 \\text{ s.t. } \\forall{n} \\leq n_0 \\\\ 0 &\\leq c_0 \\cdot g(n) \\leq f(n) \\leq c_1\\cdot g(n) \\end{aligned} ∃c0​,c1​,n0​0​>0 s.t. ∀n≤n0​≤c0​⋅g(n)≤f(n)≤c1​⋅g(n)​ Big-Theta記法は無限に大きいnnnでg(n)g(n)g(n)の定数倍にT(n)T(n)T(n)が挟まれる状態にあるということです Master Theorem 最初に定理を紹介し,あとから説明をします a≥1a\\geq 1a≥1, b≥1b \\geq 1b≥1, dddをnnnに独立な定数とします このときT(n)=a⋅T(nb)+O(nd)T(n)=a \\cdot T(\\frac{n}{b}) + O(n^d)T(n)=a⋅T(bn​)+O(nd)とすると以下の式を満たします T(n)={O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb(a))(a>bd) T(n) = \\begin{cases} O(n^{d}log(n)) (a = b^d) \\\\ O(n^d) (a b^d) \\end{cases} T(n)=⎩⎪⎨⎪⎧​O(ndlog(n))(a=bd)O(nd)(abd)O(nlogb​(a))(a>bd)​ この定理を分類定理(master theorem)と言います aaa : 分割された下位問題の数 bbb : 入力の大きさが縮む倍率(2→12 \\rightarrow 12→1のときはb=2b=2b=2) ddd : 全ての問題を分割し統合するのに必要な計算量 この定理は問題を分割し,それらを更に分割し解くという考えを使っています(これを再帰と言います) 入力がnnnの問題をT(n)T(n)T(n)で解くアルゴリズムを考えます 入力nnnをaaa個に分割する 分割された入力をT(nb)T(\\frac{n}{b})T(bn​)で解く 分割された各アルゴリズムに対してかかる時間が(O(nlog⁡b(a))(O(n^{\\log_{b}(a)})(O(nlogb​(a))である このようにするとT(n)T(n)T(n)は上のような式になります.実際にそれぞれのケースごとに正しいか確認してみましょう a=bda=b^da=bdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t=c⋅nd⋅∑t=0log⁡b(n)1=c⋅nd⋅(log⁡b(n)+1)=c⋅nd⋅(log⁡(n)log⁡(b)+1)=O(ndlog⁡(n)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t \\\\ &= c \\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}1 \\\\ &= c \\cdot n^d \\cdot (\\log_b(n) + 1) \\\\ &= c \\cdot n^d \\cdot (\\frac{\\log(n)}{\\log(b)} + 1) \\\\ &= O(n^d \\log(n)) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t=c⋅nd⋅t=0∑logb​(n)​1=c⋅nd⋅(logb​(n)+1)=c⋅nd⋅(log(b)log(n)​+1)=O(ndlog(n))​ abda abdの場合 T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満 T(n) = c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} T(n)=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​ ここで,等比級数の和は一般項xxxが1より大きい時は次数が最大の項が支配的になり,xxxが0より大きく1より小さい時は次数が最小の項が支配的になる ここでは∑t=0log⁡b(n)(abd)t\\sum_{t=0}^{\\log_b(n)}(\\frac{a}{b^d})^t∑t=0logb​(n)​(bda​)tの一般項は後者なので定数として扱える T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1未満=c⋅nd⋅定数=O(nd) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{未満}} \\\\ &= c \\cdot n^d \\cdot \\text{定数} \\\\ &= O(n^d) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1未満​=c⋅nd⋅定数=O(nd)​ a>bda > b^da>bdの場合 上の例で扱ったように一般項に注目する T(n)=c⋅nd⋅∑t=0log⁡b(n)(abd)t⏞1より大きい=O(nd(abdlogb(n)))=O(nlog⁡b(a)) \\begin{aligned} T(n) &= c\\cdot n^d \\cdot \\sum_{t=0}^{\\log_b(n)}\\overbrace{(\\frac{a}{b^d})^t}^{1\\text{より大きい}} \\\\ &=O(n^d(\\frac{a}{b^d}^{log_b(n)})) \\\\ &=O(n^{\\log_b(a)}) \\end{aligned} T(n)​=c⋅nd⋅t=0∑logb​(n)​(bda​)t​1より大きい​=O(nd(bda​logb​(n)))=O(nlogb​(a))​ Substitution Method これは以下の手順から成り立ちます 答えを推論する その推論が正しいと証明する 答えを得る 例 T(n)=2⋅T(n2)+nT(n) = 2 \\cdot T(\\frac{n}{2}) + nT(n)=2⋅T(2n​)+nという例をここでは扱います(ただしT(1)=1T(1)=1T(1)=1). 推論 この時,実際に手を動かしてみると T(n)=2⋅T(n2)+n=2⋅(2⋅T(n4)+n2)+n=4⋅T(n4)+2n=4⋅T(2⋅T(n8)+n4)+2n=8⋅T(n8)+3n=⋯ \\begin{aligned} T(n) &= 2 \\cdot T(\\frac{n}{2}) + n \\\\ &=2 \\cdot (2 \\cdot T(\\frac{n}{4}) + \\frac{n}{2}) + n \\\\ &= 4 \\cdot T(\\frac{n}{4}) + 2n \\\\ &= 4 \\cdot T(2 \\cdot T(\\frac{n}{8}) + \\frac{n}{4}) + 2n \\\\ &= 8 \\cdot T(\\frac{n}{8}) + 3n &= \\cdots \\end{aligned} T(n)​=2⋅T(2n​)+n=2⋅(2⋅T(4n​)+2n​)+n=4⋅T(4n​)+2n=4⋅T(2⋅T(8n​)+4n​)+2n=8⋅T(8n​)+3n​=⋯​ このようになり, T(n)=2t⋅T(n2t)+t⋅nT(n) = 2^t \\cdot T(\\frac{n}{2^t})+ t\\cdot nT(n)=2t⋅T(2tn​)+t⋅nになるのではないかと推測できます t=log(n)t=log(n)t=log(n)を代入し, T(n)=n⋅T(1)+log⁡(n)⋅(n)⋅n=n(log⁡(n)+1) T(n)= n \\cdot T(1) + \\log(n) \\cdot(n) \\cdot n = n(\\log(n) + 1) T(n)=n⋅T(1)+log(n)⋅(n)⋅n=n(log(n)+1) と推論できます 証明 数学的帰納法で証明します Inductive Hypothesis T(j)=j(log⁡(j)+1)T(j) = j(\\log(j)+1)T(j)=j(log(j)+1)が1≤j≤n1 \\leq j \\leq n1≤j≤nで成り立つと仮定します Base Case(n=1n=1n=1) T(1)=1=1⋅(log⁡(1)+1)T(1) = 1 = 1 \\cdot (\\log(1) + 1)T(1)=1=1⋅(log(1)+1)となり成り立ちます Inductive Step inductive hypothesisがn=k−1n=k-1n=k−1で成り立つと仮定します このとき定義からT(k)=2⋅T(k2)+kT(k)= 2 \\cdot T(\\frac{k}{2}) + kT(k)=2⋅T(2k​)+kであり,仮定よりT(k)=2⋅(k2(log⁡(k2)+1))+kT(k)= 2 \\cdot (\\frac{k}{2}(\\log(\\frac{k}{2})+1))+kT(k)=2⋅(2k​(log(2k​)+1))+kです.簡単にすると, T(k)=k(log⁡(k)+2) T(k)=k (\\log(k) + 2) T(k)=k(log(k)+2) となり,n=kn=kn=kでも成り立つことが示されました 結論 n≥1n \\geq 1n≥1 で T(n)=n(log⁡(n)+1)T(n) = n(\\log(n) + 1)T(n)=n(log(n)+1)とわかります このように事前の推論を数学的帰納法で証明することをSubstituion Methodと言います まとめ 計算量という概念を導入することでアルゴリズムの良し悪しが分かる 計算量を導く方法がある "},"comp-arch/comp-arch00.html":{"url":"comp-arch/comp-arch00.html","title":"Computer architecture","keywords":"","body":"Computer architecture "},"signal/signal00.html":{"url":"signal/signal00.html","title":"Signal processing","keywords":"","body":"Signal processing "},"signal/signal01.html":{"url":"signal/signal01.html","title":"01 Sine wave & Linear system","keywords":"","body":"01 Sine wave & Linear system "},"signal/signal02.html":{"url":"signal/signal02.html","title":"02 Complex plane","keywords":"","body":"Complex plane "},"clang/clang00.html":{"url":"clang/clang00.html","title":"C language","keywords":"","body":"C language "},"clang/clang01.html":{"url":"clang/clang01.html","title":"01 Introduction to C","keywords":"","body":"01 Introduction to C Hello Worldとは ここではC言語に入門するために最低限の知識を書きます C言語には聖典とされている(時代遅れな)本があり,その名も\"The C Programming Language\"という本です 著者であるBrian KernighanとDennis Ritchieから\"K&R\"と呼ばれています この本で最初に\"hello world\"を出力させることから入門書では最初にこの文字列を出力させることが慣習となっています ここでも｢では出力させましょう｣と行きたい所ですが,その前に環境構築をします 環境構築 環境構築とは簡単に言えばPCの設定です と言ってもPCにも色々あるので｢ gcc インストール｣(には\"Windows\", \"Ubuntu\", \"Mac\"などが入ると思います)とGoogleで検索すると記事がヒットするのでその記事に従いましょう エディタに関してはこのサイト内に記事があるのでそれを読んでくれると助かります 入門 Hello World "},"info-theo/info-theo00.html":{"url":"info-theo/info-theo00.html","title":"Information theory","keywords":"","body":"Information theory 情報理論とは情報を数量的に捉える理論のことです Entropy Information Resource "},"info-theo/info-theo01.html":{"url":"info-theo/info-theo01.html","title":"01 Entropy","keywords":"","body":"01 Entropy "},"info-theo/info-theo02.html":{"url":"info-theo/info-theo02.html","title":"02 Information Resource","keywords":"","body":"02 Information Resource "},"info-geo/info-geo00.html":{"url":"info-geo/info-geo00.html","title":"Information geometry","keywords":"","body":"Information geometry 情報理論･統計学の問題を幾何学的に解釈する学問です Basic math "},"info-geo/info-geo01.html":{"url":"info-geo/info-geo01.html","title":"01 Basic math","keywords":"","body":"01 Basic math これ以降に用いる基本事項についてこのページではまとめます 1. 逆写像定理 領域D⊂RlD \\subset \\mathbb{R}^lD⊂Rlで定義された写像 f:D⟶Rn:x=t(x1,...,xl)⟼t(f1(x),...,fn(x)) \\bm{f}: D \\longrightarrow \\mathbb{R}^{n} : \\bm{x} = {}^t\\!(x_1,...,x_l) \\longmapsto {}^t\\!(f_1(\\bm{x}),...,f_n(\\bm{x})) f:D⟶Rn:x=t(x1​,...,xl​)⟼t(f1​(x),...,fn​(x)) がx=a\\bm{x}=\\bm{a}x=aで微分可能(全微分可能)とはあるn×ln \\times ln×l行列AAAが存在して f(a+h)=f(a)+Ah+o(∥h∥) \\bm{f}(\\bm{a}+\\bm{h}) = \\bm{f}(\\bm{a})+ A \\bm{h}+o(\\|\\bm{h}\\|) f(a+h)=f(a)+Ah+o(∥h∥) と書くことができます.このときAAAはf\\bm{f}fのJacobi行列 ∂f∂x=[∂f1∂x1…∂f1∂xl⋮⋮∂fn∂x1…∂fn∂xl] \\frac{\\partial \\bm{f}}{\\partial \\bm{x}} = \\left[ \\begin{array}{ccc} \\frac{\\partial f_1}{\\partial x_1} & \\ldots & \\frac{\\partial f_1}{\\partial x_l}\\\\ \\vdots & & \\vdots\\\\ \\frac{\\partial f_n}{\\partial x_1} & \\ldots & \\frac{\\partial f_n}{\\partial x_l} \\end{array} \\right] ∂x∂f​=⎣⎢⎡​∂x1​∂f1​​⋮∂x1​∂fn​​​……​∂xl​∂f1​​⋮∂xl​∂fn​​​⎦⎥⎤​ のx=a\\bm{x} = \\bm{a}x=aでの値に一致します 陰関数定理 以下は陰関数定理というある条件を満たす時に陰関数が存在するということを示す定理です 写像F\\bm{F}F: D(⊂Rk×Rn)⟶RnD(\\subset \\mathbb{R}^k \\times \\mathbb{R}^n)\\longrightarrow \\mathbb{R}^nD(⊂Rk×Rn)⟶RnがC1C^1C1級で F(a,b)=0 \\bm{F}(\\bm{a}, \\bm{b}) = \\bm{0} F(a,b)=0 を満たし,かつその点におけるJacobi行列 ∂F∂y(a,y) \\frac{\\partial \\bm{F}}{\\partial \\bm{y}}(\\bm{a}, \\bm{y}) ∂y∂F​(a,y) が正則であるとします.このときx=a\\bm{x} = \\bm{a}x=aのある近傍U(⊂Rk)U(\\subset \\mathbb{R}^k)U(⊂Rk)とあるC1C^1C1級関数f:U⟶Rnf:U\\longrightarrow R^nf:U⟶Rnが存在して全てのx∈U\\bm{x} \\in Ux∈Uで F(x,f(x))=0 \\bm{F}(\\bm{x}, \\bm{f}(\\bm{x})) = \\bm{0} F(x,f(x))=0 が成り立ちます 逆写像定理 以下は逆写像定理という与えられた写像の逆写像の存在条件を明らかにする定理です 点a=(a1,...,an)\\bm{a}=(a_1,...,a_n)a=(a1​,...,an​)を含む領域D⊂RnD\\subset \\mathbb{R}^nD⊂RnからRn\\mathbb{R}^nRnへのC1C^1C1級写像 f:D⟶Rn:x=(x1,...,xn)⟼y=(f1(x),...,fn(x)) \\bm{f}: D \\longrightarrow \\mathbb{R}^n : \\bm{x} = (x_1,...,x_n) \\longmapsto \\bm{y} = (f_1(\\bm{x}),...,f_n(\\bm{x})) f:D⟶Rn:x=(x1​,...,xn​)⟼y=(f1​(x),...,fn​(x)) が点f(a)∈Rnf(\\bm{a})\\in \\mathbb{R}^nf(a)∈Rnの近傍でC1C^1C1級の逆写像を持つための必要十分条件はf\\bm{f}fのJacobi行列∂f∂x\\frac{\\partial \\bm{f}}{\\partial \\bm{x}}∂x∂f​が点x=a\\bm{x}=\\bm{a}x=aで正則であること,すなわち det⁡(∂f∂x) \\det\\left( \\frac{\\partial \\bm{f}}{\\partial \\bm{x}} \\right) det(∂x∂f​) が点x=a\\bm{x} = \\bm{a}x=aで000ではないということです 2. 双対空間 3. テンソル "},"os/os00.html":{"url":"os/os00.html","title":"Operating system","keywords":"","body":"Operating system Operating System(OS)とはコンピュータの基盤となるようなシステムです Introduction to OS Thread & Process C & Assembly "},"os/os01.html":{"url":"os/os01.html","title":"01 Introduction to OS","keywords":"","body":"01 Introduction to Operating System 以下にはコードが登場します Cをコンパイルした結果のアセンブリが見たいときはhttps://gcc.godbolt.org/を使ってください OSとは OSはコンピュータを動かす際に最も基本的なソフトウェアです 情報がどの記憶装置にあるのかという違いを考慮せずにプログラムを書くことを可能にします 同時に複数のプログラムが,プログラマーがいちいち書かずに動かせるようになります ブラウザ,メールクライアント,ゲームなどを並行して動かせます バグによってメモリが破壊されないようになっています 実例 Windows, Linux, Solaris, BSD, Mach,... Mac OSはBSDがベース AndroidはLinuxがベース Windows以外のOSはUnixというOSから派生 なぜ学ぶのか OSは根幹的なシステムなのでこれを学ぶことで多くの応用へと繋がります 実用プログラムの基本 OSの根本的な部分の勉強を勉強するとネットワークをプログラムから利用可能にするソフトウェアが書けるようになる ライブラリ,プログラミング言語などで使われる機能の実装方法を理解できます セキュリティへのより深い理解 効率的なプログラムとそうでないプログラムを理解することができます OSは高速にプログラムの間を切り替えて実行おり,その中の動きを理解しなければプログラムに対する選択の良し悪しがわかりません OSの細かい機能はどうでも良いという人 OSののAPIを組み合わせる際に,OSを持つ機能を理解していれば必要に応じてマニュアルを見るという正しい手法をすることができます マニュアルを読む際にOSの背景知識が必要になることが多く,マニュアルを読んで理解することも可能です OSの役割 OSには以下のような役割が有ります 計算機資源を抽象化･仮想化します プロセス間の隔離,計算機資源の管理 抽象化･仮想化(便利な側面) ハードウェアとソフトウェアの間に入るような機能を提供しています(仮想化) ナマのハードウェアではやりにくい出入力などを扱ったり,OSを簡単に扱えるようなAPIを提供しています また,実際は複数のプログラムで計算資源を共有しているのですが,それを意識しなくても使うことができます(抽象化) CPUやメモリでプログラムの資源の割当をうまくしています プロセス間の隔離,計算機資源の管理(安全な側面) プロセス間の隔離とは他の人が自分のプログラムを閲覧したり,破壊できないようにする機能です 計算資源の管理とはあるユーザーがCPUやメモリを独占的に利用できないようにしています システムコール システムコールを呼び出すことで,実行が面倒な仕事(入出力,計算資源の割当)を実行できます また,システムコールを介してでないと資源を利用できないようにすることで安全性を保証しています 安全性をどう実現をするのか ファイルを読み書きするシステムコールはopen, read, writeです(便利な側面) これらを通してしかファイルにアクセスができないようにすれば安全です しかし,その保証は自明ではありません というのもディスクにアクセスするというプログラム,OSの動作の真似をすれば誰でもアクセスができそうです CPUの仕組み 命令･モード 命令には2種類あります 非特権命令 特権命令 CPUの動作状態にも2種類あります ユーザーモード(非特権) スーパバイザモード(特権) CPUによっては更に細分化する場合が有ります 特権命令(入出力命令,一部のメモリ領域へのアクセスなど)は特権モードでのみ実行可能とします これによって普段行っているプログラムは非特権命令なので,保護をすることができます トラップ命令 トラップ命令とは｢特権モードへ移行+特定番地へジャンプ｣という命令です ｢特権モードへ移行｣という命令と｢特定番地へジャンプ｣という命令を同時にすることで他の命令では実現できないようにできます トラップ命令はユーザモードで実現可能です 特定番地を決めるのは割り込みベクタと呼ばれるメモリ上の表です 割り込みベクタは特権命令によって設定されます 安全性のためのOSの仕組み アプリケーションが特権命令を実行しようと思った時は, システムコール(トラップ命令)→特権命令(非特権命令も使う) ここではアプリケーションとOSをシステムコールが結び,OSとCPUを特権命令が繋いでいます(非特権命令も) まとめ スレッドとプロセス(CPUの抽象化･管理) 仮想記憶,アドレス空間(メモリの抽象化･管理) ファイルシステム プロセス間通信(ソケット) 認証とセキュリティ "},"os/os02.html":{"url":"os/os02.html","title":"02 Thread & Process","keywords":"","body":"02 Thread and Process スレッド･プロセスの目的 CPUを仮想化することができます 物理的なCPUの数は固定,少数,有限 PCやスマホは大概8コアまで サーバーでも数十 しかし,それ以上のプログラムを立ち上げることが可能です ここのプログラムを書く人が明示的な譲り合いをする必要はありません スレッドとは スレッドとは制御の流れ OSが｢スレッドを作りたい｣と要求 OSがスレッドにCPUを割り当て実行 OSが交互にスレッド実行し,CPUが複数あれば各CPU上スレッドを作ります プロセスとは プロセスとはプログラムを起動したときにできるもの 言い換えるとプロセスとは｢論理アドレス空間の生成+mainスレッド(1つ以上のスレッド)の生成｣ 実際には Linux: ps, top, htop Windows: perfmon などで現在走っているプロセスを見ることが可能です 関連API スレッド･プロセスに関連するAPI 共通する主要概念 生成･終了 同期･実行の制御 代表的スレッドAPI Unix: POSIX Threads(pthread) Windows: Win32 thread 代表的プロセスAPI Unix: POSIX Windows: Win32 プロセス生成 Unix プロセスを作ること自体はforkで終わっています execvでは,現在のプロセスを新しいプロセスイメージで置き換え実行します pid = fork(); /* プロセス複製 */ if (pid == 0) { /* 子プロセス */ execv(file, cmdline); /* fileを実行 */ } else { /* 親プロセス */ } Windows fileをコマンドラインcmdで起動します CreateProcess(file, cmd, ...., &pid); プロセス終了 プロセスの終了はWindowsとUnixで以下のように行われます Win: ExitProcess(s) Unix: eixt(s) またはプログラムのmain関数が終了した時に自動的に終了します プロセス終了待ち プロセスpidが終了するのを待つAPIは以下の通りです Win: WaitForSingleObject(pid, timeout) Winは待つ時には同じAPIを使います Unix: wait(&status) waitpid(pid, &status,...) 高水準なAPI Unixの場合,最終的にはfork, exec, waitpidなどの組み合わせに過ぎません system(command_string) command_stringを実行するプロセスを作り終了を待ちます fork+exec+wait popen(command_string) command_stringを実行するプロセスを作り,そのプロセスと通信するチャネル(パイプ)を返します pipe作り+fork+exec スレッド生成 命令列が始まるアドレスを指定します そこから実行を開始するスレッドを生成します 命令列のアドレス=Cの関数ポインタ スレッド生成実例 f(x)を実行するスレッドを生成し,スレッド名をidに格納する関数は以下の通りです Unix: pthread_create(&id, ..., f, x) Wind: CreateThread(..., ..., f, x, ..., 'id) スレッド終了 sとは'status'のことです スレッド終了実例 Unix: pthread_exit(s) Win: ExitThread(s) また,生成時に指定された関数がfが終了すると自動的にスレッドは終了します スレッドの終了待ち スレッドidが終了するのを待ちます idはpthread_craeteなどによって得られたスレッド名です スレッド終了待ち実例 Unix: pthread_join(id, &return_status) Win: WaitforSingleObject(id, timeout) その他の言語 ほとんどの言語でスレッド,プロセス関係のAPIは提供されています (上ではC言語が例ですが, Java, C++, Pythonなどでも同様) 名前が異なることは多いですが,概念は似ています 多くの場合はC言語用のライブラリからfork, execなどを呼び出しているだけです(Unixの場合) プロセスとスレッド 両者は似ているように思えますが,実際に違います 現時点では スレッド...一筋の実行の流れ プロセス...プログラムを起動した時にできるもの 箱+1個以上のスレッド mainを実行するスレッドはプロセスと共に自動的に作られます スケジューリング システムには多数のスレッドが同時に存在します 多くの場合ではCPUの数 OSの役割は適切にCPUを割り当てることで,そのためにスケジューリングが必要になります スケジューリングの目標 公平性 独占的に割り当てないようにします 公平にCPUに割り当てます 効率性 実行可能なスレッドがある限り, CPUが休まないように動かせます スレッド切り替えのときのオーバーヘッドを少なくします 対話的プログラムの応答性 スケジューラの挙動を観察する いくつかのスレッドを立ち上げます スレッドがいつからいつまで実行中だったのかを調べます これには時刻を知るシステムコールが必要です 観察する点 どれくらいの頻度でスレッドが入れ替わっているのか その状態でのエディタやブラウザの応答性に影響はあるのか f(x) { t1 = currentTime(); while(1) { t2 = currentTime(); if (t2 - t1 > 1) { /* CPUをしばらく使われている */ } t1 = t2; } /* 記録を出力 */ } 時刻を知るシステムコール Unix: gettimeofday Win: QueryPerformanceCounter 特定のCPUへスレッドを固定 システムコール sched_setafinity(pid, size, mask) mask: size bitのbit列 maskで1となっているCPUでのみ,pidを実行 子プロセスへ自動的に継承 コマンド taskset -c command スレッドスケジューラの実現 クイズ 無限ループするプログラムを書いて実行してもマウスが動き,ブラウザが動き,(多くの場合)Ctrl-Cで消せるのはなぜ? 割り込み処理がされるから OSのないCPU クイズのような答えに成るのはCPU自体の動作は以下のようになっているからです CPUの状態はレジスタに入っています 汎用 プログラムカウンタの入っている命令を実行する CPUモードに応じて操作が制限されています CPUの動作は >> PC(プログラミングカウンタ)が指す場所の命令を取り出す命令を実行し状態を書き換える 割り込み処理 割り込みとはCPU外部からの信号のことです 割り込みの時にCPUが行うことは以下のようになっています if (割り込み許可中) { 割り込みを禁止する一部の状態(割り込み発生時PC(など))を特定のレジスタに保存割り込みベクタを参照し指定されている値をPCに設定(制御の移動) > } 割り込みベクタ 割り込みベクタとは割り込みの要因を示す番号のことです CPUに直接命令をします 割り込みベクタは通常OSの起動時に設定されます IRQ IRQとはキーバード･マウスなどの入出力デバイスがCPUを呼び出す時に生じる割り込み要求のことです IRQの通常の用途 入出力 キーボード･ネットワークコントローラ タイマ システムコール(トラップ命令) タイマ割り込み これはCPUの独占を防ぐための鍵です 通常定期的に発生させます(1-10ms程度に1回発生します) Linux(2.4) on x86, Windows on x86, BSDなどで10ms Linux on Alpha 1ms Linux 2.6.22以前は1ms, 4ms, または必要に応じて発生させます タイマ割り込み間隔･クロック間隔･クロックチックなどと呼び,必要な時にOSがCPUをアプリケーションから奪う機会を保証します 各スレッドの状態 中断状態 中断状態とは(CPUが空いていても)直ちに実行することができない状態のことです OSは中断状態のスレッドをCPU割当の対象から外します 中断と復帰 スレッドが中断する理由 入出力待ち(recv, read, etc) 自主的休眠(sleep) スレッド間の同期(pthread_join, wait, etc) ページフォルト 復帰の理由(中断の逆) 入出力完了 休眠時間経過 スレッド間の同期成立 ページフォルト処理完了 実行可能キュー 実行可能キューとは実行可能スレッドのリストのことです ｢スケジューリングキュー｣,｢ランキュー｣などという名前で呼ばれることがあります スレッドが実行可能キューにあるといことはそのキューが実行可能であるということです OSが機会あるごとに実行可能キューから最も適切なスレッドを選んで実行することをrescheduleと呼びます 中断 ネットワークからのデータ待ちによる中断を例とします recv() { ... if (読むべきdataがない) { 現スレッドを実行可能キューから外す reschedule() } ... } 中断からの復帰 ネットワークからのデータ到着による復帰を例とします /* 割り込み→OSのネットワークからの入力を処理 */ if (あるスレッドが今到着したデータ待ち) { そのスレッドを実行可能キューに入れる reschedule() } Rescheduleの機会 OSが制御を得るあらゆる時点が潜在的なrescheduleの機会です タイマ割り込み時 クロック間隔に一度 その他の割り込み(入力)からの復帰時 実行スレッドが中断した時 システムコードからの復帰時 etc rescheduleの機会をOSが得るたびに｢次に実行すべきスレッド｣を選択して実行します.つまりCPUの割当をしています 次に実行すべきスレッドの選択の仕方が重要です 公平性 効率性 対話的プログラムの応答 対話的なスレッドの応答性 エディタ,ブラウザ,メーラに｢キー入力｣をしたらすぐに反応してほしいです これに対応する対話的なスレッドは基本的には｢入力待ち｣です.そして以下の特徴が有ります I/Oによる中断が非常に頻繁 キーボード,マウス,ネットワークなどの入力待ち 中断が多いため,CPU利用量は少ないです 現在のLinuxスケジューラ カーネル2.6.23以降はCompletely Fair Scheduler(CFS)が使われています 特徴としては 各スレッドが使用したCPU時間を累積で管理しています vruntime(virtual runtime) reschedule時には毎回vruntimeが最小のスレッドを選びます つまり最もCPUを使っていないスレッドを選びます 公平性の保証をしています vruntime管理の実際 vruntimeは以下のように管理されています スレッドが生まれた時 子は親のvruntimeを引き継ぐ 子のvruntime = 0とはならない スレッドがAからBに切り替わる時 Aのvruntime += 今回消費した時間 Bのvruntime = そのまま しかしそれでは問題があります Bのvruntimeは最初0なとき,他のスレッドのvruntimeが100msだったときに100msも動かせます それではまずいのでBのvruntime (他のスレッドの最小vruntime) - 20msを保証します "},"os/os03.html":{"url":"os/os03.html","title":"03 C & Assembly","keywords":"","body":"03 C & Assembly 目標 Cプログラムの実行を機械語レベルで｢イメージ｣できるように成ることが目標です なぜやるのか 本来,OSやCPUは言語に関係ないです OSはプログラムがどの言語で書かれていようと関係のない言語で設計されています システムコール(API)の引数や返り値は整数やアドレスであり,Javaの配列やPerlの文字列ではないです CPUもあくまで機械語しかわかりません スレッドがメモリを共有をしているのはC言語の処理系がやっているのではなくCPUとOSが提供しています 機械語ですべてやるのが正しいですが,それでは不必要に複雑になるという理由でC言語で説明します.また, システムコールのAPI説明はCの関数で説明するのが慣習 スレッドがメモリを共有していることをC言語の変数や配列が共有されていることとして説明するのが慣習 C言語を理解するメリット 初級 ポインタを理解できます mallocなどアドレス関連の関数を理解できます Segmentation Faultを理解できます 中級 ポインタと配列の関係を理解できます 関数呼び出しの実装に関して理解できます 上級 C/C++言語ならではの理解不能バグを理解できます 中心的なテーマ Cプログラムによるメモリの使われ方について学びます 変数,配列がどこに格納され,どのようなCの式,文がどのようにメモリをアクセスされるのか 関数呼び出しの仕組み ローカル変数の格納場所(スタック) 呼び出しの入れ子の実現 制御構造,副プログラム,名前空間など CPU & メモリ コンピュータはレジスタと呼ばれるCPU内の少量の記憶領域とメインメモリと呼ばれるCPU外の記憶領域を用いて計算を行う機械です 主記憶にはプログラムが使うあらゆるデータが格納されています ブラウザで開いているタブ,Terminalなど C言語の変数,配列など 主記憶は単なるバイト列です 主記憶へはアドレスを指定して記憶場所を指定します 番地は単なる整数です 番地として許される値にはある一定の制限が有ります Cのプログラムもメモリをアクセスしているだけと言うことが可能です そのため,｢常に変数,配列,などなどあらゆる記憶域がメモリのどこかにプログラムが正しい限り重ならないように格納されている｣ということを考慮してください ポインタ ポインタとはつまりアドレスのことです char* p = ...; pに格納されているものはアドレス(整数) *pはpに格納されているアドレスをアクセスします p[5]はpに格納されているアドレス+5番地をアクセスしますす p[0]は*pの糖衣構文(syntax sugar)です 実践 int main() { char* p = 918; return *p; } このプログラムを実行するとエラー文が出てきます.それはOSをが間違った･悪意のあるプログラムからシステムを保護するために動いたからです(メモリ保護) 一般的な用語としてメモリ保護違反をすることにはSegmentation FaultというUnix用語を使います 変数のアドレスを見るには以下のようなプログラムを書きます &x; // xの値が格納されているアドレス #include int s; // 単純な変数 typedef struct point{ int x; int y; } point; point p; // 構造体の変数 int a[10]; // 配列 int main() { printf(\"%d %d %d %d %d %d\\n\", &s, &p.x, &p.y, &a[0], &a[5], &main); } 実はアドレスなもの int x &x; // 変数のアドレス int a[10]; a; // 配列 int* s = \"abc\"; s; // 文字列 int* q = malloc(100); q; // メモリ割り当て関数の返り値 int* p = 918; p; // 実はアドレスは整数値 C言語と他の言語の違い どんな言語も究極的には機械語(整数･浮動小数点しかない)です.つまり,メモリに色々なものをおき,そのアドレスで表している仕組み自体は同じです C言語の特徴はその｢仕組み｣をポインタという形で包み隠さず見せているところです.混乱の原因でもあり,自然かつ単純なところでもあります ポインタと配列の違い /** アドレス1個文の領域を確保 * そこに勝手なアドレスを格納できます * intを格納するための領域は確保されていません */ int* p; /** int 10個分の領域を確保します * aはその先頭のアドレスです */ int a[10]; ポインタに関する知識 int foo{ int a[100]; int* p; a[0] = 10; // OK p[0] = 10; // NG: どこにアクセスするか決まっていない } ポインタ変数へは初期化の必要があります int a[10]; int* p = a; // 以下は同じ a[0]; // p[0] a[3]; // p[3] (a+5); // (p+5) // 以下は異なります &a; // &p C言語で現れる3種類の記憶療育 大域(global)静的(static)変数･配列 関数外に書かれた変数･配列 関数中でstaticと書かれた変数･配列 局所(local)変数･配列 関数定義の中に書かれた変数定義 ヒープ malloc, new(C++)などで確保される 大域/静的 // 大域変数 int x; int a[10]; void foo() { // 静的変数 static int y; static int b[10]; } プログラム開始時に各変数,配列があるアドレスに割り当てられ,プログラム終了までその領域はその変数,配列のために確保され続けます つまり,そのアドレスは他の目的には使われません 局所 int fib(int n) { if (n fib(10)とfib(9)ではxは別の領域である必要が有ります 実際にどのように実装されているかと言うと,スタックというデータ構造を用いて,関数が呼び出された時にその呼び出しの実行のための領域を見つけて確保します スタックとは上から新しいものを入れて,上から取り除くようなデータ構造です 実際には以下のようなアルゴリズムでスタックに変数が格納されます 関数が実行を開始する時 その関数が使う局所変数の大きさに応じて空き領域からメモリを確保します 関数が終了する時 開始時に確保した分だけメモリを開放します 確保･開放とはスタックポインタをずらすことです 各スレッドが一つのスタックを持っています 局所変数･配列はそれを確保した関数呼び出しが終了すると開放されます スタックに関する知識 ほとんどのOS/CPUではスタックは大きい番地から小さい番地へ向かって伸びます 確保: SP -= size; 開放; SP += size; 小さい番地には命令列,大域変数,ヒープなどがありその方が都合が良かったのでは?と推測できます 現在ではスレッドが増えたので同じ手法ではできません また,スタックは無限に伸びないので使いすぎるとスタックオーバーフローを起こします.原因は以下の通りです 巨大な局所配列 深すぎる関数呼び出しの入れ子 スタックの大きさはスレッド生成時に指定できます 戻り番地 戻り番地とは関数終了後にジャンプする番地のことです スタックにはこの戻り番地が格納されています 戻り番地が破壊されることをバッファオーバランと言います デタラメな番地に行ってしまうので,セキュリティホールの原因となります しかし,デタラメな番地で済まずに攻撃する側が実行した命令が実行されるということも... ヒープ 確保 開放 大域変数･配列\\n静的変数･配列 プログラム開始時 されない(プログラム終了時) 局所変数･配列 関数開始時 関数終了時 ヒープ 任意(malloc, new) 任意(free, delete) "},"other/editor.html":{"url":"other/editor.html","title":"Editor","keywords":"","body":"Editor "},"other/latex.html":{"url":"other/latex.html","title":"Latex","keywords":"","body":"Latex "},"other/git.html":{"url":"other/git.html","title":"Git","keywords":"","body":"Git "}}